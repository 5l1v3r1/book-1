
## Monitoring, troubleshooting and disaster recovery

We talked about deploying to production in the previous chapter, but just _being_ in production is only half the job. 
The other half is ensuring that your systems are up, running and answering queries faster than your SLA thresholds. 
In this chapter, we are going to cover how you are going to tell that your RavenDB cluster is healthy, monitor its 
state over time and what actions you should take if there are any issues popping up.

Even before getting the production deployment ready, you need to plan on how you'll monitor what is going on with 
RavenDB. The first thing you'll see when you go to the RavenDB Studio in the browser is the dashboard view, giving
you the most important details about what is going on with this RavenDB instance. This surfaces crucial details such
as the number of requests, CPU load, memory utilization, indexing rate, etc. 

The dashboard view was designed so you can just throw it on a monitor and take a peek every now and then to measure
the health of your system. If you have nothing else, just looking at the dashboard should still be enough to give you
some idea about what is happening on a particular node.

The problem with relying on only the RavenDB dashboard is that it shows you what is going on right now, and only on a 
single node. This isn't so useful if you want to have aggregated statistics across your cluster, including historical
information and analysis of behavioral patterns over time. For that, you need to use a dedicated monitoring system. 
RavenDB does not attempt to build a full blown monitoring solution in the dashboard, only to provide you with the most
pertinent information. The expectation is that you'll plug RavenDB into your existing monitoring solutions. Let's 
explore what kind of hooks are provided to plug into a monitoring solution by RavenDB.

### Ongoing monitoring

The most obvious monitoring option is to use SNMP^[Simple Network Management Protocol], which is available in 
RavenDB for Enterprise licenses. To configure SNMP in RavenDB you will need to setup SNMP as shown in Listing 16.1.

```{caption="Setting up SNMP using the settings.json configuration file" .json}
{
    "Monitoring.Snmp.Enabled": true,
    "Monitoring.Snmp.Port": 161,
    "Monitoring.Snmp.Community": "password"
}
```

Once you have the configuration options in Listing 16.1 in the `settings.json` file, restart the node and you can 
start querying RavenDB's internal state using SNMP. 
For example, the command in Listing 16.2 fetchs the server update from the public RavenDB test instance. 

```{caption="Getting the live instance server update via SNMP" .bash}
$ snmpget -v 2c -c ravendb live-test.ravendb.net 1.3.6.1.4.1.45751.1.1.1.3

iso.3.6.1.4.1.45751.1.1.1.3 = Timeticks: (84790246) 9 days, 19:31:42.46
```

The key parts of the commands are:

* `-v 2c` specify the protocol version to use (RavenDB uses RFCs 1901-1908)
* `-c ravendb` the community string (in the case of the public instance, it uses the default `ravendb`). If you use the 
  configuration in Listing 16.1, it will be `-c password`, etc. 
* `live-test.ravendb.net` the hostname to use, in this case, we use the live instance, but you will plug your own 
  instance URL there, of course.
* `1.3.6.1.4.1.45751.1.1.1.3` the OID that we are querying, in this case, we are asking for the server uptime.

The output is the server uptime, and we told RavenDB that we wanted this value using the OID. 
OID stands for Object Identifider, which is a way to globally name a particular value. The 
[`1.3.6.1.4.1.45751`](http://oidref.com/1.3.6.1.4.1.45751) prefix belongs to RavenDB and anything nested under that
is used to denote particular values that can be queried. Instead of making you memorize all of those OIDs, you can 
ask RavenDB to give you a list of all the OIDs that are supported by a particular instance. 

Querying the available OIDs is done by calling to the `/monitoring/snmp/oids` endpoint on your server. For the live
test server, that would be 
[http://live-test.ravendb.net/monitoring/snmp/oids](http://live-test.ravendb.net/monitoring/snmp/oids).

The later can be very helpful because it also gives you the OID for specific values in specific databases. For 
example, the `1.3.6.1.4.1.45751.1.1.5.2.2.2.1` OID can be used to tell us how big in MB is a particular database.
This can make it very easy to plot all sort of interesting values over time. You can also use this to monitor 
the index rate of a specific index in a particular database. The amount of details and control you have is extensive.

Of course, you aren't usually going to be querying SNMP OIDs using `snmpget`, you are going to be plugging this 
directly into a monitoring solution such as Zabbix, Nagois, SCOM, OpenView, etc. The online documentation has a few
walkthroughs to help you setup some common scenarios, but I'm going to assume that you are familiar with your own
monitoring systems and will skip any further handholding at this point.

> **RavenDB isn't the only source of monitoring data**
>
> RavenDB exposes a lot of information about its internal state to make it easier to figure out what is going on.
> At the same time, we don't try to expose _machine_ state via SNMP. RavenDB assumes that you can get that directly
> from the machine using standard monitoring metrics (`1.3.6.1.2.1.25.3.3` OID to get per core CPU load, for example).
>
> When setting up monitoring, be sure to include metrics for anything that is useful. CPU, memory, network and I/O 
> are among the most common values that should be tracked. In most systems, these are part of the standard templates
> and require very little effort to setup. I mention this explicitly because tracking just the values that RavenDB
> can provide will paint only part of the picture. 

Beyond using SNMP, RavenDB also expose a lot of state in REST endpoints outputting JSON that you can use. 
These are meant to both for humans to look at during troubleshooting and for automated systems to scrape and store
the data over time. Most monitoring solutions have a way for you to provide a URL and a path in the response to gather
interesting values to keep. 

You can get the full list of the debug endpoints from your server's `/debug/routes` endpoint. For the live test server
this would be [http://live-test.ravendb.net/debug/routes](http://live-test.ravendb.net/debug/routes). Just like any
other endpoint in RavenDB, when running in a secured mode, you'll need to authenticate using a client certificate. 
Each monitoring solution have a different way of specifying that, so you'll need to check the user's manual for
exactly how that work.

#### What should be monitored?

Now that we know how to get the values to monitor, the obvious question is what _should_ be monitored? 
I'm afraid that this is a hard question and a lot depends on your actual usage and needs. CPU, memory, network and 
disk I/O are the most obvious things that you want to pay attention to.
The number of requests and number of writes are also very interesting in almost all cases. 

> **Why not just monitor _everything_?**
>
> You can most certainly capture and store all the values that RavenDB and the machines expose. The problem with 
> looking at all of them is that there are a lot of information there that has no value for most scenarios, so 
> you might end up with a needle in a haystack situation. It's easy to fail to see the pertinent information because
> you are drowning is so many other details.

You most certainly want to monitor values such as the number of alerts for each of your databases, but seeing the 
time since last query for each index is probably not that interesting. 

The general recommendation is that you'll start with the basic template (see the online documentation for more 
details on that) and add more details as you see the need for that. A lot of that depends on whatever you are 
seeing some signs of trouble and you want to head them off early on.

This is vague, I'm aware, but the problem is that it is very hard to give good advice in a generic manner. One
scenario may call for B2B system with fairly constant load, so seeing CPU percentage go too low or too high is 
a good indication that something is not right. Another scenario would be a user facing system where during 
lunch time there is hardly any activity, but there is a very clean 9AM spike very single working day. 

There is no substitution for knowing your environment and what is expected. Once you know that you can set
set thresholds for alerting the operations team when the monitored values are not in the expected range. Some
monitoring tools can even analyze the data on their own and detect when there are irregularities in the data
and point that out for you. 

#### Performance hints and alerts

RavenDB itself is constantly monitoring its own health. This includes measuring I/O latencies, conenctivity
to other nodes in the cluster, amount of memory and disk that are available, etc. For some of these values, RavenDB
will take direct action. For example, if the memory is low, RavenDB will switch gears and try to reduce the 
amount of memory it is using to avoid running completely out of memory. 

Most of the time, however, there isn't much that RavenDB _can_ do. For example, if there is no free space on the 
backup folder or if RavenDB is experiencing slow I/O. What RavenDB can do is let you know about these 
troublesome details. RavenDB expose such issue as performance hints and alerts, shown in Figure 16.1.

![Alerts and performance hints give your operations team hints about what to look at](./Ch16/img01.png)

Alerts are issues that RavenDB encounters that require some sort of manual intervention. It may be something simple
such as running out of disk space or network issues talking to a particular database. Sometimes the errors are 
transient, which is common in network scenarios. They'll generate an alert for your perusal, even if the actual 
error was fixed (connection resumed between the nodes) because it can be important to investigate what happened
after the fact.

> **Alerts are node-local**
>
> An alert isn't a cluster wide notification. Indeed, in many cases, you'll be alerted that a node is unable to 
> talk to the rest of the cluster. As such, you need to monitoring each node in the cluster and check its state
> whenever there an alert. 

Performance hints, on the hand (the blue box Figure 16.1) are different. These aren't things that denote errors, 
but they very likely do demand attention. RavenDB generate them for various reasons, such as the slow I/O sample
in Figure 16.1. Other reasons include queries that return very high number of results without using streaming, 
slow requests, high fanout in indexing and a few other common issues.

These aren't typically of high severity, but it is better to fix them early. These kind of hints are generated 
whenever RavenDB detects a usage pattern that is known to be problematic. For example, if your queries have a
very large page size, or your documents are very big, these are commonly cause for issues. RavenDB will be 
proactive in bringing these to your attention. 

In general, alerts are designed as an acknowledgement that no one reads the logs until it is too late. Instead
of hiding errors in a text file that no one reads, RavenDB ensures that your operations teams know about the 
stuff that they need to.

#### The debug log

Alerts are high level items that needs operator attention, by design, there are very few of these and RavenDB will
avoid spamming your operations team with too many cries for attention. In addition to the alerts and hints system, 
there is also the debug log.

RavenDB has just two log levels: `Operations` and `Information`. By default, RavenDB will log only messages 
with the `Operations` label. Operational log messages are things that the operations team need to pay attention to
or be aware of. That include actions such as updating certificates, failure to process commands, background tasks
errors, etc. 

At this level, the logs output is meant to be readable and fairly shallow. You aren't informed about anything that
goes on inside RavenDB. You only hear about the kind of stuff that should matter to the operations teams. That is
mostly errors and issues, even if they were transient or worked around by RavenDB.

> **The audit log**
>
> In addition to the `Operations` level, RavenDB also support an explict audit mode, in which RavenDB will record
> all connections to the database, the source of the connection, the certificate used and what access level was
> granted to the connection.
>
> Certain special actions, such as creating databases or indexes are also written to the aduit log. To enable the
> audit log, you can set `Security.AuditLog.FolderPath`. We covered the audit log in more details in Chapter 13. 

The `Information` level, on the other hand, is much more detailed and will include a detailed log of anything that
goes in the database. That can be helpful when tracking down a specific issue, but generally that results in a _lot_
of data that goes to the log. On a busy server, you can easily see a log file rollover (which happens every 256MB)
in 5 - 10 minutes.

By default, RavenDB retain log files for 72 hours. After that, it will delete the old log files. In many cases, 
you'll have a logs agent monitor the directory and send the logs to a central location, which means that you can 
delete the logs file as soon as RavenDB starts a new one.

The logs location is controlled by `Logs.Path` configuration option and it generally recommended to have RavenDB
write the logs to a separate hard disk. This is primarily to avoid the case of setting the `Logs.Mode` to the 
`Information` level and have the logs fill up the RavenDB data disk completely. 

Changing the logs path or the logs mode requires a server restart. But that isn't the only way you can use to get
information from RavenDB.

### Finding out your server is doing

If you run into issues with RavenDB, it might be too late to setup logging and monitoring. Recognizing this reality
RavenDB has a lot of knobs to tweak and places to peek into the internals of the engine. This does _not_ mean that you
can skip setting up proper monitoring regime. The techniques outlined in the section are very useful when trying to 
understand the behavior of RavenDB.

In many cases, they can help you pinpoint what is going on very quickly. Monitoring, on the other hand, gives you 
insight into the behavior of the system over time and alert you if something is out of whack. It is expected that
any production cluster will have a proper monitoring strategy.

The RavenDB Studio provide explicit support to figure out what is currently going on. The first place to look at is
inside `Manage Server` and the `Debug` section, shown in Figure 16.2.

![The `Debug` section is your first stop to figure out what is going on the inside](./Ch16/img02.png)

These options are typically only available to the operations team (requiring `Operator` or `Cluster Admin` privileges).
This is because they contain data for the entire server, not for a particular database. A standard user will not be
able to use these features. 

Let's explore each one of these options in turn.

#### The admin logs view

The easiest way to figure out what is going on inside RavenDB is to use the `Admin Logs` feature. This allow you to 
hook into the logs stream that is generated by RavenDB and view that on the browser. It is a very convient option 
because it doesn't require you to do anything to the server.

Even if the server is configured to not log anything, going to the `Admin Logs` page will start streaming the log
entries to you at `Information` level. This means that you can enable the logs and watch them only during interesting
periods, instead of having them on all the time (or having to restart the server to change the logs mode).

Errors will be highlighted in red, but do note that there are many errors that are actually expected and handled by
RavenDB, so seeing some errors isn't something that you should be frightened of. 

#### The traffic watch view

Looking at the logs can be fairly tedious, given how much information is being generated. In some cases, it is easier
to figure out what is going on by just looking at the requests that are being made. RavenDB contains a dedicated
view for that, as you can see in Figure 16.3. 

![Watching live requests on a production database can be helpful in many cases](./Ch16/img03.png)

In Figure 16.3 you can see each individual request, how much time it took as well as some statistics about all the 
requests that were captured during a specific session (number, min, avg, max duration). That can be very helpful if 
you want to figure out why something is slow or result in an error. You can also export the traffic capture for 
later analysis. 

#### The debug info package

By far the most valuable tool to inspect the state of RavenDB is the `Gather Debug Info` page. You can see how this
looks like in Figure 16.4. 

![The `Debug Info` pacakge gives us access to _all_ the RavenDB debug endpoints](./Ch16/img04.png)

What this page does is to give us the ability to generate, at the click of a single button, a snapshot of the current
state of the RavenDB instance or even the whole cluster. The result is a single `zip` file that you can send along 
with your support ticket or do offline analysis at a later date.

I mentioned a few times before that RavenDB goes to great lengths to externalize its state. Even with this chapter, 
dedicated to talking about how you can figure out what RavenDB is doing, I'll not have enough time and space to go
over all the details that are available. Some of them are extremely useful, for a single specific case. Most of the 
time, you don't really need to go over each and every one of them.

The ability to capture all the state at once, easily and with no fuss, means that if you are in a bad state, you can
get the current status of the system and then take potentially invasive operations to fix this. The classic example
is rebooting the system, which will "fix" many issues. The problem is that if you do so, you'll also typically lose
crucial information about what went wrong and how to prevent it in the future. 

The `Debug Info` package allows you to retain all of that knowledge. It also is very useful if you need to contact
the RavenDB support team, since it saves a _lot_ of back and forth. 

#### Advanced details

The last item in Figure 16.2 is the `Advanced` options, where RavenDB puts details that can be very interesting, but
aren't usually needed. Among them, we have two very interesting views.
You can see these in Figure 16.5.

![Advanced information about what is going on inside RavenDB](./Ch16/img05.png)

Figure 16.5 shows the threads details inside RavenDB. This can tell you what exactly is costly in terms of CPU time. 
The list is sorted by usage order, so threads that burns through a lot of CPU will show up first. In this case, you 
can see that the most expensive thread is the `Voron Global Flushing Thread` (we'll discuss I/O, which is what this
thread is doing, later in this chapter) and then an indexing thread. 

RavenDB typically names threads to make it easier for you to figure out what is it that they are doing. This allows
the operations team to figure out what is costing you and take actions accordingly. 

Another interesting peek into the internals of RavenDB is offered by the `Cluster Observer Logs` view. 
In Chapter 7 we discussed how RavenDB Cluster will assign work and even move databases between nodes automatically.
Figure 16.6 shows the logs of such decisions, allowing you to examine and understand them.

![The cluster observer logs explains how the cluster makes decisions](./Ch16/img06.png)

The logs in Figure 16.6 shows that Node B was down, and at what point the cluster detected that this node's databases
caught up with the rest of the nodes in the database group, allowing the cluster to move node B from a rehab state
to a normal member state.

> **Operational stability**
>
> One of the worst things a piece of software can do to an operations team is to surprise and mystify them. 
> Surprises are almost never a good idea in production. And a good mystery is wonderful when it comes in book
> form, but not if it means figuring out what blew out production. 
> 
> The cluster observer routinely  monitor the health of the entire cluster, making
> decisions about where traffic should go and what nodes are reliable. 
> By default, it is only going to take action if a node is down for a long time (15 minutes or more). 
>
> This means that it isn't going to start taking action before you can react. You can also ask the cluster 
> observer to suspend any actions for a while, if you know that you are going to take some maintenance operation
> that will make the observer take action usually. This is done using the `Suspend cluster observer` button shown
> on Figure 16.6. 

This can be very useful if you want to understand how the system got into its current state, and what has led the
cluster observer to make the decisions it did. This is also logged, of course, but it is usually much easier to 
see the information condensed in such a manner than search through the log files. 

### I/O operations in RavenDB

As a database, I/O _matters_ to RavenDB. In particular, I/O performance. A lot of problems in production can be tied
directly into issues with I/O. And I/O issues typically come with one (or both) of the following:

* insufficent depth - the I/O system cannot handle the amount of data read/write fast enough. 
* insufficent width - the I/O system cannot handle the number of concurrent read/write requests fast enough.

Both these issues are going to end up looking like slow I/O, but their root cause are different. In the first case
we have an I/O system that gets requests that are too big for it. A good example of that is trying to make a large
write (greater than the buffer size, typically) and seeing very high latency for the write.

> **Imagine I/O bandwidth as a shipping channel**
>
> I use the terms depth and width here because of the following metaphor. Imagine a shipping channel that has ships
> going through it. If you have a ship that is heavily loaded, it is sitting deep in the water and if the channel
> doesn't have enough depth, it will hit the bottom. In our cases, the I/O request will usually still work, but
> _very_ slowly. 
>
> As for the width of the channel, imagine a shipping channel that have a lot of canoes 
> going through it. The bigger the width of the channel, the more concurrent canoes can go through. But if the 
> channel has insufficent width, you are going to see a traffic jam. The same with I/O. If you have a lot of 
> requests (even if they are individuall very small) the I/O system might struggle to serve them all.

If you are running on an HDD and making a lot of random reads, which requires seeking (which is slow). For a single
continuous write, the HDD is wonderful (high depth). But for concurrent work, not so much (insufficent width).

If you are wondering how to spend your hardware budget, get better I/O, it is almost always going to be a good
idea. With the way RavenDB handles memory, if you have a fast enough disk (NVMe comes to mind) you can even trade
off the amount of memory the machine has. Getting the memory mapped data from NVMe disk is usually fast enough that
it doesn't need to reside in main memory for many scenarios.

> **What to look out for?**
>
> Watch the disk queue length. If the queue length grows, it is usually a sign that there are requests waiting
> for the I/O system. If the disk queue length is high for long period of times, that means that there is I/O
> starvation and your database is likely suffering.
>
> High disk queue length means that some form of action is required (upgrading hardware, increasing IOPS, changing
> the load pattern, etc). 

RavenDB will alert you if it detects slow I/O for writes, as you already saw in Figure 16.1. But for more detailed
I/O monitoring you will need to look in more places. RavenDB makes this easy and gathers all its I/O statsitics for 
writes in one place. In the RavenDB Studio, go to your database and then go to `Stats` and then to `IO Stats`.
You can see how this looks like in Figure 16.7.

![RavenDB's internal stats for I/O write operations for a production database](./Ch16/img07.png)

There are a lot of details in Figure 16.7, and it probably won't make sense in isolation. In the studio, you can zoom
in and out and insepct every detail in the performance graph. That can give you a lot of insight into any particular
operation that was made by RavenDB.

The green bar on the bottom is the most important datum. There you can see the cost over time of writes to the journal
file. A transaction cannot complete before it has durably written its changes to the journal file, so that is the 
number one hot path for any issues with slow writes.

The size of each write indiciate how long it took and the color tells you how big it was. The darker the value, the 
bigger the write. In general, you want to see a healthy situation, with mostly small and thin writes. Having a few
wider and darker spots is also fine (it may take longer to write more, obviously). However, if you see wider areas
that are birght (small writes that took a long time) that is usually an indication that the I/O system is saturated.

In such cases, you want to turn to the operating system own tools to figure out what is going on. Some ideas about
what you should be looking for and how to get it are showing in Table 16.1.

|          |        Windows         |    Linux    |
|----------|------------------------|-------------|
| Tool     | `perfmon`              | `iostat`    |
| Counters | Disk Reads/sec         | `r/s`       |
|          | Disk Writes/sec        | `w/s`       |
|          | Avg. Disk Queue Length | `avgqusz`   |
|          | Avg. Disk sec/Transfer | `await`     |

Table: I/O monitoring tools and what metrics to look at.

Table 16.1 is a good start to investigate why your systme is showing slow I/O sympthoms. You can also use Resource
Monitor in Windows and `iotop` / `sysdig` on Linux to figure out what files exactly are taking all the I/O.

> **Do you have enough IOPS?**
> 
> When running on the cloud, a surprisingly common mistake is to forget to reserve enough IOPS for your data
> disks. In many cloud providers, you have some sort of burst capability, after which you'll be throttled. In 
> that case, you will see initial good performance (until the burst window is done) and then your I/O performance
> will drop sharply. This is the very first thing to check for I/O issues when running on a cloud.
>
> When running on your own hardware, talk to the storage team and ensure that the database server has good enough
> QoS rating to be sufficent for the workload you have on it. I have seen cases where RavenDB was put on a powerful
> server, backed by a SAN full of speedy drives, and the Quality of Service setting restricted the database to 
> about 5% of the available resources. 

In this section, we looked at how to gether information about what is going on. Whatever it is via RavenDB and
the `I/O Stats` graphs or through the operating system tooling. What we are still missing is how to make this
actionable. In order to know what to do when you have I/O issues, we need to understand how RavenDB is using I/O.

#### RavenDB I/O behavior

The graph in Figure 16.7 shows how RavenDB is keeping track of its writes. In general, RavenDB writes mostly to 
documents and to the indexes. Each write is done first to the journal (the green bar in Figure 16.7) and then flushed
to the data file (blue bar). Every now and then RavenDB will sync the data to disk (using `fsync`) to allow us to
reuse the journal files.

> **Flushing data and syncing to disk**
>
> RavenDB use the term `data flush` to denote the process of copying modified transaction data to the memory mapped
> data file. This operation is typically very fast, since it works by copying from memory to memory, involving no
> disk I/O. Every now and then RavenDB will ensure that the data written to the data file actually resides on disk
> by calling `fsync`. This is a `data sync`, and it is typically much more expensive operation. 

It's important to understand that within a given storage environment (the documents store for a database, or each
individual index) there can only be a single outstanding write, data flush or file sync. However, writing to the disk, 
flushing the data and syncing to disk can all run cocnurrently.

Each index is also a full blown storage environment, so indexes will have their own cycle of journal writes, data 
flushes and fsync calls. Each of those run completely independently from other indexes and the documents store. When
you have multiple databases inside the same server, each database and each one of the indexes will also operate 
independently and concurrently of each other. 

> **What about reads?**
>
> I went over a lot of details about how RavenDB writes data, but what about reads? How is that handled? 
>
> All of the read I/O operations in RavenDB are done using memory mapped I/O. In other words, we let the operating
> system buffer cache to manage what is resident in memory and when to read from the disk. In most cases, the
> operating system will know how to select an effective working set that will minimize the amount of I/O required
> for RavenDB.
>
> If that isn't the case, for example if you don't have enough physical memory for the workload you have, you'll 
> start seeing high number of page faults. In particular, pay attention to hard page faults. A small number of them
> is expected, but it you are seeing a jump is the number of hard page faults/sec counter, that indicate a possible
> issue.
>
> If you are using fast disks, you might not care about this. NVMe reads are fast enough that in some cases they 
> can replace main memory, for example. Or you might be reading cold data because you have created a new index that
> need to go over the existing documents.
> But in most cases, seeing high hard page faults/sec is indicative of an issue and require investigation. 

By default, RavenDB limits the number of concurrent syncs and flushes that are perform per physical device, to avoid
overwhelming the disk with too many concurrent writes. This is controlled by the `Storage.MaxConcurrentFlushes` and
`Storage.NumberOfConcurrentSyncsPerPhysicalDrive` options. 

For best performance, having each database use its own device is recommended, in this way, they don't have to fight
for the same hardware resources. For that matter, you can also dedicate specific drives for indexes or journals by
using symbolic links and junction points, as discussed in the previous chapter.

#### Inspecting used disk space

RavenDB uses storage, for what?

Compaction

### Troubleshooting connection issues




### The admin JavaScript console

Through the studio and the console.


### Disaster recovery

- Voron.DisasterRecovery
- How to bring a cluster up from a single node
- rvn and the ravendb cli
- recovering the keys to a cluster