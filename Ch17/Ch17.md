
## Backups and restores

Backups are _important_. I don't really think that I need to tell you how much. At the same time, we need to discuss what is the
point of having backups. There are two reasons to have backups:

* Restore the database after losing the data.
* Recover data from an earlier point in time.

Let's consider each one of them independently. Restoring after data loss can happen because an operator accidently deleted the
wrong database, the hard disk or the entire server died, etc. 
I intentionally picked these two examples, because they represent very different scenario. In the later case, a hardware failure
resulting in the loss of a node, the other members in the cluster will just pick up the slack. You can setup a new node or 
recover the old one and let the cluster fill in any missing details automatically^[Remember that any single node system cannot
have any uptime SLA, since a single node failure will bring it all down.].

The case of accidental deletion of the database is more worrying. In this case, the database is gone from all the nodes in the
cluster. At this point, what can save you is an offsite replica. By that I mean a database to which you had an exteral 
replication setup. Because it isn't part of the same database group, it will not be impacted by the deletion, and you can 
manually fail over to it while you replicate the data back. 

> **Restoring databases can take time**
> 
> The scenario of deleting a database, or losing a whole cluster seems like the perfect reason why you'll want to have a backup.
> Why wouldn't we just restore from backup at this point? The answer is simple, _time_.
>
> Imagine that we have a decent size database, 250GB in size. Just copying the raw data from the backup destination to the machine
> on which we want to restore can take a long time. Let's assume that we have a Provisioned IOPS SSD on Amazon Web Services 
> (high speed hard disk recommended for demanding database loads). Ignoring any transport / decompression costs, the raw speed in 
> which you can write to a disk like that means that it will take about 10 minutes just to copy the backup to the local disk, and 
> another 10 minutes (with just I/O costs, ignoring everything else) for the actual restore. 
>
> That gives us a minimum of 20 minutes for the restore, assuming we are using a high end disk and are only limited by the speed
> of the disk itself. However, the I/O costs aren't the only thing to consider and the actual restore time can be higher. Most
> of the cost for restoring a database is actually spent it getting the data to the machine, by the way. Backups are often 
> optimized for long term storage and speed of access is not prioritized (tape storage, for example).
>
> Because of this, if you are interested in minimizing downtime in such scenarios, you would have a separate offsite replica that
> you can use. We discussed this at length in the previous chapter. There is a balance between how much protection you want and
> how much you are willing to pay for. If your threat scenario does not include an admin deleting a database by mistake or losing
> the entire cluster in one go, you probably don't need this.
> Alternatively, you may decide that for such a scenario, the time to restore from backup is acceptable.

The option of restoring the database to a particular point in time is used a lot more often than restoring after data loss. This
can be very helpful in many cases. You might want to restore from backup on an independent machine, to try to troubleshoot a 
particular problem, or to see what was in the database at that time. In many cases, there are regulatory requirements that backups
should be kept for a certain period of time (often a minimum of 7 years).

In short, backups are _important_, but I said that already. This is why I'm dedicating a full chapter for this topic and why 
RavenDB has a whole suite of features around scheduling, managing and monitoring backups. We'll start by going over how backup
works in RavenDB, to make sure that you understand what are your options and what are the implications of the choises you make.
Only after that we'll start setting up backups and performing restores. 

### How backups work in RavenDB

Backups are often stored for long periods of time (years) and as such, their size matter quite a lot. The standard backup option
for RavenDB is a gzipped json dump of all the documents and other data (such as attachments) inside the database. This backup
option gives you the smallest possible size for your data and make it easier and cheaper to store it. On the other hand, when 
you need to restore the data, RavenDB will need to re-insert and re-index all the data. This can increase the time that it takes
to restore the database.

> **Avoid backing up at the files on disk**
>
> It can be tempting to try to backup the database at the file system level. Just copy the directory to the side and store it
> somewhere. While it seems easy, this is _not_ supported and likely to cause failures down the line. RavenDB has an involved
> set of interactions with the file system, with a carefully choreographed set of calls to ensure ACID compliance. 
>
> Copying the directory to the side will usually not capture a point in time of the data and is likely to cause issues. When
> creating backups, RavenDB ensures that there is a point in time freeze of the database at a particular point to handle
> this scenario. In short, you should be using RavenDB's own backup system, not rely on the file system for that.

An alternative to the backup option is the snapshot. A snapshot is a binary copy of the database and the journals at a 
given point in time. Like the regular backup, snapshots are compressed, but other than that, they are pretty much ready 
to go as far as the database is concerned. 
The restore process of a snapshot involves extract the data and journal files from the archive and starting the database normally.

The advantage of a snapshot is that it is _much_ faster to restore the database, but it is also typically much larger than a 
regular backup. In most cases you'll have both a regular backup defined for long term storage (where the restore speed doesn't
matter) and a snapshot backup written to immediately accessible storage (such as local SAN) for quick restores. 

Both backups and snapshots perform a full backup of the database. In other words, this is a full clone of the database at the
point in time in which the backup started. However, there are many cases where you don't want to have a full backup everytime.
You want just the changes that happened from the last backup. This is called incremental backup and is available for both
backups and snapshots.

Incremental backup is defined as the set of changes that happened since the last backup / snapshot. Regardless of whatever you
use a backup or a snapshot, an incremental backup is always using gzipped json (RavenDB doesn't do incremental snapshots). The
reason for that is that applying incremental backups to a snapshot is typically very quick and won't significantly increase the
time to restore the database, while incremental snapshots can be very big. One of the primary reasons incremental backup exists
in the first place is to reduce the cost of taking backups, after all. 
Figure 17.1 shows the interplay between snapshots, full backups and incremental backups from a real production database (my blog).

![Snapshot, full backup and following incremental backups for the `blog.ayende.com` database](./Ch17/img01.PNG)

In Figure 17.1 you can see a snapshot taken on April 17th at 2 AM on node A as well as two incremental backups after that. The
second folder shows a full backup on April 16th at 2 AM and two incremental backups after that. In both cases, the database 
is the `blog.ayende.com`, which powers my personal blog. The database size on disk is 790MB, so you can see that even for 
snapshots, we have quite a big space saving. On the other hand, this is a pretty small database. Figure 17.2 shows the same
snapshot / backup division for a database that is about 14 GB in size. 

![Snapshot and backup for a large database on S3](./Ch17/img02.PNG)

The reason why even snapshots are so much smaller than the raw data is that the backup is compressed, even for snapshots. 
The cost of decompressing the backup is far overshadowed by the cost of I/O at such sizes. However, encrypted databases
typically cannot be compressed, so you need to be prepared for snapshots that are the same size of the database (_very_ big).

In Figure 17.1 you can see that there are only a couple of incremental backups, and in Figure 17.2 we have a lot more. This
is because (while both backups were defined with roughly the same incremental backup duration) they show very different 
databases. The blog database is seeing infrequent writes, and when the incremental backup runs and see that there have been
no changes since the last time, there is nothing for it to do, so it skips a backup run. On the other hand, whenever a full
backup run, even if there have been no changes, you'll still get a full backup.

On the other hand, in Figure 17.2 we are backing up a database that is under relatively constant write load, so you'll see
an incremental backup on every run, although you can see that there are significant differences between the sizes of the 
incremental backups. 

> **Incremental backups record the current state**
> 
> An important consideration for the size of incremental backup is the fact that the _number_ of writes don't matter as
> much as the number of _documents_ that have been written to. In other words, if a single document was modified a thousand
> times, when the incremental backup runs, the latest versin of the document will be written to the backup. If a thousand
> different documents were written, we'll need to write all of them to the backup.
> That kind of difference in behavior can produce signficiant size changes between incremental backups. 

Backups record the current state of documents, but if you want to get all the changes in between, you can use revisions.
And just like documents, revisions are also included in the backup. This means that even if you store revisions inside
your database for a short period of time, you can still restore a document to any point in time by digging into the 
relevant revision from historical backups.

#### What is in the backup?

A backup (or a snapshot) contains everything that is needed to restore the database to full functionality. Table 17.1 shows all
the gory details about what exactly is being backed up. This requires us to understand a bit more about where RavenDB store
different information about a database.

|  Database   |           Cluster                    |
|-------------|--------------------------------------|
| Documents   | Database Record (including tasks)    |
| Attachments | Compare exchange values              |
| Revisions   | Identities                           |
| Tombstones  | Indexes                              |
| Conflicts   | Tasks state (snapshot only)          |
         
Table: What is backed up for a database and at what level. 

We already discussed the differences between database group and the cluster (see Chpater 7). At the database level we manage 
documents and any node in the database group can accept writes. At the cluster level, we use a consensus algortihm to ensure
consistency of changes for the database. Such operations include identities, creating indexes, etc.
These details are stored at the cluster level and are managed by the cluster as a whole, instead of independently on each node.

> **Incremental backup of cluster level state**
> 
> At the cluster level, RavenDB dumps the entire cluster level state of a database to the backup on any backup (full or 
> incremental). If you have a _lot_ of identities (very rare) or plenty of compare exchange values (more common), you might
> want to take that into account when defining the backup frequency. 

Identities and compare exchange values can be very important for certain type of usages and they are stored outside of the
database itself. When we backup a database, the cluster level values are also backed up. Another important factor is the database
tasks, such as the backup definitions and schedule, ETL tasks, subscriptions, etc. 

#### Important considerations

When the database is restored, the tasks that were defined to it are also restored. In other words, if you have an ETL task
defined for a production database and you restore the backup on a development machine, you need to disable the tasks. Otherwise,
assuming your development server can reach the ETL targets, it might start running these tasks and writing to places you don't
want it to.

The same apply to external replication, backups and any other tasks that was defined for the database. The restore includes all
these tasks, which is what you want when you restore a down node, but it is something to note if you are restoring a backup on
the side. During restore, you have the option of disabling all such tasks, so you'll have restored the database cleanly, but
have to manually select which tasks to re-enable. That option should be set when you are not restoring the bacup to
the same environment (and purpose) as before.

If you are using encrypted databases, you need to be aware that the snapshot backup has the actual data still encrypted, but all
the cluster level data are stored in plain text (even if the server store itself is encrypted). And regular backups are always
in plain text. As part of your backup strategy, you need to consider the security of the backup themselves. You can read more 
about backups and encrypted databases in Chapter 14.

#### Backing up of the cluster itself

We talked about backing up databases, but what about backing the cluster as a whole? In general, the cluster is mostly concerned
with managing databases, there isn't any persistent state beyond the database data that needs backing up. If you'll look at 
Table 17.1, you can see that all the details there, whatever they are stored at the cluster level or the database level are all
for a particular database.

The only details at the cluster level that aren't directly related to a database are about the cluster itself (nodes, topology, 
task assignments, history of health checks, etc). All of that data isn't really meaningful if you lost the entire cluster, 
so there is no real point in preserving that. 

Backups in RavenDB are always at the database level. Recreating the cluster from scratch take very little time, after all. Once that
is that you can restore the individual databases on the new cluster. 

#### Who is doing the backup?

A database in RavenDB is usually hosted on multiple nodes in the cluster. When it comes to backup, we need to ask a very important 
question, who is actually going to run the backup? Individual database instances in the database group are independent of 
each other but hold the same data. We don't want to have each of the nodes in the database group create their own backup. That 
would lead us to create duplicated backups and wasting a lot of resources.

A backup task, just like ETL tasks or subscriptions is a task that is set for the entire database group. The cluster will decide
which node in the database group is the owner of this task and that node will be the one in charge for running backups. The 
cluster know to pick a node that is up to date and will move the responsability for the backups to another node if the owner
node has failed.

For full backups, this doesn't matter. Any node will perform the backup from its current state as usual. If the cluster decdied that
a different node will execute the backup, they are clearly marked and timestamped. From an operational perspective, there is no
difference between the nodes in this regard.

For incremental backups, the situation is a bit different. You can only apply an incremental backup on top of a full backup from the 
same node that took it. When the cluster decides that incremental backup ownership should switch bcause the owner node is down, the
new node will not run an incremental backup. Intead, it will create a _full_ backup first, and only then it will start creating 
incremental backups.

> **Backups from different nodes to the same location**
> 
> RavenDB encodes the node id in the backup folder name. In such a way, even if you had a backup triggered from multiple nodes
> at the same time, you can tell which node was responsible for which backup. This scenario can happen if there is a split in 
> the network, when the owner node of the backup is unable to communicate with the cluster, but is still functional.
> 
> At this point, the cluster will assign someone else as the owner for the backup (since the original node is missing in action,
> as far as the cluster is concerned). At the same time, the original node didn't get the ownership change from the cluster,
> obviously. That can cause both the original and the new node to run the backup.
> The reason for this behavior is that we want to ensure that we always take backups and prefer to have an extra backup rather
> than go without.

Consider the case of a three nodes cluster and a database that is configured to take a full backup every midnight and an incremental
backup every four hours. Node C is the node that is usually assigned to do the backups and indeed, on midnight it took a full backup 
as well as dutifully created the incremental backups at 4 AM and 8  AM. However, at noon, node C is down and the cluster has moved the
responsability for the backups to node A. 

Node A cannot create an incremental backup on top of node C's full backup this will
trigger a full backup from A. If node C is still down at 4 PM node A will still own the backup task and create an incremental
backup since noon. When node C comes back up at 6 PM, the cluster will transfer the backup ownership back to it. At 8 PM node C will 
create an incremental backup (everything since 8 AM, the last time node C took an incremental backup). 

There are a few interesting behaviors that you might want to pay attention to here:

* The cluster ensures that at all times the minimal backup definition is respected. In other words, every 4 hours we'll have an 
  incremental backup of the node's state. 
* Only nodes that are up to date with the database state are considered candidate for backup ownership. If node C was down for 
  so long, it is probably out of date. The cluster will only transfer ownership of the backup task (as well as any other tasks)
  when the node has caught up with any changes that happened while it was down.
* Incremental backups apply from the last backup (incremental or full) on that particular node. This means that you can use a 
  single node backup to restore the datbase state fully.
* When the cluster moves the ownership of a backup from nodes, the new owner will first run a full backup (even if only an 
  incremental backup was scheduled to run). This is a good rule of thumb to remember, but it is actually a bit more complex. 
  On backup task reassignment, the new node will check whatever it has done a full backup in the defined duration, if it did
  then only an incremental backup will run (from the last full backup for this node).

The last two points are important for a simple reason. Even though you might have scheduled your full backup to happen during
off hours, a new owner for the backup may cause a full backup to run at a time where you expect an incremental backup. This can
be an issue because of the cost of actually doing a full backup can be high in terms of disk I/O, CPU, etc. If you are running
this at a time when you are under high load (and especially as you already lost at least one node) this can put additional 
pressure on the server. 

To handle that, RavenDB control the amount of resources that a backup can take. The I/O and CPU priority for the backup task 
equals to the normal request processing priority, which is higher than the usual indexing priority. This will likely 
only be an issue if your system is teetering on resource exhaustion as it is. 

Now that we know how backups behave in RavenDB, let's go ahead and see how we configure backups in RavenDB.

### Setting up backups

Backups in RavenDB are setup using the Studio^[You can also setup backups through the API, of course.] by going to `Settings`, 
`Manage Ongoing Tasks` clicking on `Add Task` and selecting `Backup`. You can see how the backup screen looks in Figure 17.3.

![Defining a backup schedule for every Saturday at midnight](./Ch17/img03.png)

In Figure 17.3 we have defined a Backup that is scheduled to run a full at 00:00 AM every Saturday. As you can see, RavenDB
uses cron expressions to define recurring backup schedules. In the case of the backup shown in Figure 17.3, we have defined
only a weekly full backup. The incremental backup duration is empty, so no incremental backups will be generated. 

You can see in Figure 17.3 that we didn't select the preferred mentor node. This lets the server assign any node to this task.
On the other hand, even if we chose a preferred node, if that node is down at the time of the backup, the cluster will still
re-assign that task to another node so the backup will happen. 

> **When will my backup run?**
> 
> Time is an awkward concept. In the case of a backup schedule, we have a few conflicting definitions for time:
>
> * The server's local time.
> * The admin's local time.
> * The user's local time.
>
> In some cases, you'll have a match between at least some of them, but in many cases, that will not be the case. 
> When you define a backup schedule for RavenDB, we _always_ use the server local time.  Because this can be 
> confusing, you can see that Figure 17.3 lists the time in triplicate. Once in the server local time (what you
> actually defined), once in the admin's own time and once as a time duration for the next backup. 

You can save the backup as it stands, but that won't really do much. This is a backup that has no destination, so it
is effectively disabled. In order to actually get the backup to do something, we need to tell it where to write the 
backups to. RavenDB supports the following destinations:

* Local / network paths
* FTP / SFTP
* Amazon S3
* Azure Storage
* Amazon Glacier

Figure 17.4 shows how you can define a backup task that will write to a local folder as well as to an Amazon S3
account. The backup will run _once_ each time it is executed, and the backup files will be sent to all the specified
destinations from that single source.

![Setting up multiple destinations for a single backup task](./Ch17/img04.png)

The backup process will run and first write the backup to the local path (or to a temporary path if there is local
path is not specified). Once that part is done, the backup runner will start uploading the backup to all the remote
destinations (in parallel). If any of the remote destinations fail, the entire backup will be considered to have 
failed. 

> **Removing old backups**
> 
> RavenDB does absolutely nothing to remove old backups. This is because there isn't a single good policty that 
> RavenDB can apply in such cases. Instead, RavenDB relies on the operations team to set things up properly. That
> can take the shape of a cron job that will delete backup folders that are too old. This can be as simple adding
> the following to your crontab:
> 
> `0 4 * * * find /path/to/backup/* -type d -mtime +14 -delete`
>
> This will run every day at 4:00 AM and delete all the directories older than 14 days. If you don't have something
> similar to this, backups will accrue until you run out of disk space. In particular, be _very_ careful about 
> setting backups to the _same_ volume as your database is using. There have been many not so humorous at the time
> incidents where the backup took the entire disk space and cause RavenDB to reject writes because there is no more
> space for it.
>
> For remote backups, you'll need to decide what is your policy. It is fairly common to never delete backups in the 
> interest of being able to go back in time. Given how cheap disk space is today, that can be a valid strategy. 

The local backup option also supports network paths (so you can mount an `NFS` volume or use `\\remote\directory`)
and it treats it as if it was a local file. If you define both a local path and a remote one (for example, Azure Storage)
RavenDB will first write to the local path and then upload from there. If the local store is actually a remote one, that
can increase the time to complete the backup.

When selecting the local path, take into account that the backup task may run on different nodes. It is usually better
to use a path that is either an absolute path (after verifying that it is valid on all machines) or a relative paths.
In the later case, the path is relative to the RavenDB executable, not the database location.

I'm going to skip going over the details of each of the backup options, the online documentation does a good job in
covering them and you can probably figure out how to use them even without reading the docs. Let's look at what 
the backups look like after we have defined them.

#### Inspecting backup state

After defining the backup schedule and the backup destinations, you can click on `Save` and the studio will take
you back to the `Manage Ongoing Tasks` page where you'll see the task distribution across the cluster, as you can see
in Figure 17.5.

![The backup tasks automatically distributed between the nodes in the database group.](./Ch17/img05.png)

Figure 17.5 shows how the studio is making it apperant where each task will run. And in Figure 17.6 you can see how
we can get full details on the backup tasks for a particular database. You will need to expand the backup 
tasks for the full details by pressing the details icon.  

![The backup status for each of the backups defined for this database.](./Ch17/img06.png)

Figure 17.6 shows the last successful full and incremental backups as well as the time of the next scheduled backup. You
can also see that you can trigger a backup immediately. Note that the backup will run on the assigned node, not on 
the source node. In this case, even if I'm access this view from node C, if I'll press `Backup now` on the first backup
(which is assigned to node A) it will be executed on node A. 

Backups tasks are always defined as scheduled tasks to run automatically and RavenDB will make it explicit if you haven't 
done so. Figure 17.7 shows how this is done. There is no backup defined for `users.northwind` so RavenDB makes sure that this
is clearly visibile to the operators.

![The backup status for each database is shown as integral part of the database details](./Ch17/img07.png)

You can also see in Figure 17.7 that the last backup status is shown right there in the databases view. This is an 
important piece of information and RavenDB makes sure that it is clearly visible for the operator. 

This concludes the backups topic. You now know everything about how to setup and schedule backups in RavenDB. But 
we aren't actually done, backups are just half the job, we now need to talk about how we are actually going to handle
restores. 

### Restoring databases

We talked about how to generate backups, but the most important parts about backups is actually utilizing them by restoring
a database from backup. RavenDB attempts to make the restore process simple and obvious. To start the restore process you'll
need to go to the `Databases` view in the Studio and click on the cheveron near the `New database` button then select 
`New database from backup`. The result of this is shown in Figure 17.8.

![Setting out to restore a database](./Ch17/img08.png)




Important to practice, can take a LONG time.

How to restore to a single node
How to restore to the whole cluster.

Managing the encryption keys!

#### External replication as a backup strategy

Delayed

### Restoring whole clusters