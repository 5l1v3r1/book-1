	
## Counters and Time Series in RavenDB

The previous chapter covered the RavenDB client API and focused on using RavenDB as a document database. This is the 
most common usage scenario for RavenDB, but it isn't the only one. We looked into attachments
in the previous chapter, as a way to add binary data to documents. In this chapter, we are going to talk about using
RavenDB to store counters and timeseries.

Like attachments, counters and time series are strongly tied to a document. Unlike attachments, we aren't talking about
just storing binary data and calling a day. With both counters and time series, RavenDB support complex operations and 
the ability to understand and work with the data in non trivial ways.

But before we get to the gist of these features, let's talk about why does RavenDB even need to have dedicated features
such as these? Surely we can just store the data in the document itself and call it a day, no?

Consider the document fragment shown in Figure 5.1, in the image, you can see how we can store counters and time series
data directly in the document. So why do we need a dedicated feature for something that is already there?

![Document fragment storing counters and time series data](./Ch05/img01.png)

The answer is quite simple. If the data is inside the document, any change to the data means changing the document as a
whole. Consider the case of the `DownloadsCount` that we have in Figure 5.1. If we need to update it whenever a user 
click on a download link, what are the implications?

We can load the document, increment the count and save it back. This works, unless there are two users who click on the 
link at the same time. We can use a `Patch` operation to avoid concurrency issues, of course, but at the database's side
of things, RavenDB will still need to load/modify/store the document. 

Another important aspect is what happens when we have _other_ changes to the document while we are incrementing the 
value. Similar concerns apply to the `DailyDownloads` field as well. But in addition to the concurrency aspect of 
counters, with time series we have to take into account that the _size_ of the data might grow very big. To the point
where most of the document's data would be the time series data. And while we certainly want to keep track of that, we 
don't want to keep it in the same place as the document itself.

We have talked about different ways to handle that, with splitting the logical document into separate physical 
documents in the previous chapter. But a much better option is to have support for these scenarios directly inside 
RavenDB, which is why we have these features.

### Counters

Counters in RavenDB are pretty simple. They are just named signed 64 bits values that can be attached to a document. 
At first glance, they don't look like much. But the concept of counting is so pervasive that it turns out that they 
are quite useful in many scenarios. 

Figure 5.2 shows a counter in the Studio. As you can see, this is quite similar to the way you would use this value if
it was embedded inside the document. The only thing we have done so far is just move it aside a bit. 

![A document counter in the Studio](./Ch05/img02.png)

Moving the counter to the side is actually the whole point. Because now we can treat the counter in several special 
ways. To start with, changing the counter does _not_ require us to change the document. This means that when we want
to increment or decrement the value, we don't need to load / modify / store the document. That reduce the cost of 
changing the value of the counter. 

#### Writing counter values

Updating a counter value is cheap, _very_ cheap. This fact allows us to nicely handle many interesting cases. 
Consider the scenario of two users clicking on the download link at the same time. Listing 5.1 has the code that 
will increment the number of downloads for the document.

```{caption="Incrementing the number of downloads of a document" .cs}
using (var session = store.OpenSession())
{
    session.CountersFor("packages/393-A")
    	.Increment("DownloadsCount", delta: 1);
    session.SaveChanges();
}
```

The code in Listing 5.1 has a few interesting implications. First, as usual, a change to counter is part of the session
and has the same transactional guarantees as other operations in RavenDB. You can have a document change and a counter
increment (to the same document or to a different document) that will all be part of the same transaction.
Second, concurrent operations on the counter are safe to perform and will simply resolve to the appropriate value after 
taking into account all the operations on that particular counter. Third, we don't need to create our counter ahead
of time. The first operation on a counter on a document will create the (zero initialized) counter. 
This reduce the amount of work you have to deal with when working with counters.

> **Counters are natively distributed**
> 
> Counters not only handle concurrent modifications to the counter safely and correctly, they also handle the problem
> of _distributed_ concurrent modifications. Two clients may update the same counter on the same document 
> on two separate nodes in a  RavenDB cluster, and RavenDB will know how to resolve all those writes to get 
> to the right value in the end.
>
> RavenDB uses a data structure called CRDT^[Conflict-free replicated data type] for this purpose, 
> which allows us to merge multiple writes and reach the correct tally without the need for synchronization 
> or complexity on the part of the users. 
>
> Under the covers, RavenDB maintains a value per each node the counter was modified on. So we can merge all those
> values together to get the final tally for the counter, without having to coordinate in a distributed system.

These features make RavenDB counters highly suitable for tasks that require high level of concurrency in counting. The 
example of `DownloadsCount` is a good representation of the kind of usage you'll get from counters. Counters are used
for capturing ad impressions, page views and tracking the number of API calls across your system.

> **Decrementing a counter value**
> 
> RavenDB doesn't provide an API call to `Decrement` a value. You can simply pass a negative value to `Increment`
> to reduce the counter value.


#### Reading counter values

After looking at writing counter values, let's see how we can read them. In Listing 5.2 you can _read_ counters values.

```{caption="Reading a counter value via the Session API" .cs}
using (var session = store.OpenSession())
{
    long? downloads = session.CountersFor("packages/393-A")
    	.Get("DownloadsCounter");
}
```

The API is fairly simple, all you need to state is what document you are operating on and what counter's value you want
to get. You get the value back as a 64 bits number, and that is pretty much it. Well, almost.

In order to get the counter value, you need to make a remote call to the server. In Chapter 2, we talked about the 
high costs of remote calls and how RavenDB has the notion of Includes specifically to avoid these costs. Counters can
also be included, as you can see in Listing 5.3.

```{caption="Including a counter value during document load to reduce remote calls" .cs}
using (var session = store.OpenSession())
{
	var package = session.Load<Package>(
		"packages/393-A", 
		i => i.IncludeCounter("DownloadsCount")
	);
    long? downloads = session.CountersFor("packages/393-A")
    	.Get("DownloadsCounter");
}
```

The `Get` call in Listing 5.3 will not trigger a remote call to the server. The data has already been been gathered by
the session in the `Load` call, because we explicitly asked for it. The RavenDB Client API has various overloads to 
get all the counters for a document, a specific counter or a set of them. The end result in all cases is that you can
reduce the number of round trips that you have to pay for and gain better overall performance.

> **Including counters in queries**
> 
> We have barely talked about queries so far (we'll do so quite extensively in the 3rd part of this book). But as a 
> sneak peak, you can also include counters during queries, like so: `from Packages include counters('DownloadsCount')`.
> And you can get all the counters for a document using: `from Packages include counters()`.

#### Counters metadata and data modeling

Counters are stored outside of the document itself, as we previously discussed. However, the document itself does 
contain some information about the counters. Most importantly, the document's metadata contains two important
properties relating to counters, as you can see in Figure 5.3.

![Looking at counters metadata in the studio](./Ch05/img03.png)

The first property of interest is the `@flags` property. You can see that in the case of Figure 5.3, its value is 
`HasCounters`. The `@flags` property is used by RavenDB to surface a lot of the internal state of the document and
you can make use of it in your code to make decisions about the document.

The second property of interest here is the `@counters` property. This is a metadata property that holds an array 
of all the counters names that exists on this document. In other words, merely the act of loading a document 
will give you access to all the counter names that this document possesses. If the only thing you use counters for
are for things like download metrics, the `@counters` property isn't particularly interesting. 

There are far more interesting scenarios for using counters, however. To the point where we need to talk about 
data modeling with counters. On initial consideration, data modeling with counters seems... odd. There isn't much
to _do_ with counters. Each counter represent a signed 64 bits number, which can range between  
`-9,223,372,036,854,775,808` to positive `9,223,372,036,854,775,807`. What kind of data modeling do we have in this case?

The data modeling part isn't so much for the values, but for the counters _names_. Consider a scenario where I want
to track downloads not just globally, but also by location. I can use a `DownloadsCount` to track the global number
but also have `Downloads/EU` and `Downloads/USA` as counters and increment them as well, based on the source of the 
download. 

Another good example would be to track the number of requests to a 3rd party service. We may want to keep track not 
just on the number of requests, but also their results. Figure 5.4 shows a simple way to handle this task.

![Tracking request HTTP statuses via counters](./Ch05/img04.png)

The advantage here is that counters are small and efficient, designed to be used in scenarios that demand high 
throughput. Using them to track high frequency events, and using different counters to track different statuses of 
the event can simplify such tasks greatly.

> **How many counters?**
>
> A document can have any number of counters attached to it. We have tested documents that had hundreds of thousands
> of counters, so there isn't a _hard_ limit. However, you should be aware of practical realities. 
>
> The names of counters on a document are stored in the document metadata. If you have a document that have a _lot_
> of counters, the size of the document's counters' metadata might grow to be a significant portion of the
> document size. That is not a desired scenario. Things would still work, but you can do better by
> splitting the data to multiple physical documents at that point.

You can also use counters in queries, as you can see in Listing 5.4.

```{caption="Getting the values of counters during queries" .sql}
from Services as service
select service.Name, 
	counter(service, "status/500") as Errors
```

We'll cover queries in depth in Part III of this book, so I won't go over these in detail. But you can probably already
see how useful such a feature can be. In this case, you don't need any special API calls, the resulting value is sent
as a simple property of the result set of the query.

#### Consistency properties of counters

Counters in RavenDB are resilient to concurrency and distribution issues. You can increment or decrement a counter 
at the same time on multiple nodes that are wildly separated from one another and RavenDB will gather all the 
operations on the counter and reconcile them to a single final value. 

RavenDB ensures the ability to mutate counter values concurrently in distributed environment for existing counters as
well as new counters. For existing counters, we need to merge the disparate counter values. Changing a counter value,
after all, does not change the document. That is the whole _point_ of counters.

Creating a new counter, however, does change the document. In particular, the name of the new counter is written to
the document metadata. That means that two writes to separate counters on the same documents on different machines will
create (slightly) different documents. RavenDB is aware of this and will resolve conflicts on the `@counters` property
automatically for you.

The fact that you can freely mutate or create a counter in a distributed environment without care is valuable 
and useful in many scenarios, but it comes at a cost.

RavenDB guarantees that writes to counters are ACID. That is, if you make a write to a counter, we'll accept the write
and persist it. Even in the presence of failure. If the counter write is part of a larger transaction (such as 
modifying multiple counters and / or documents), we also guarantee that the whole transaction (including the counter 
writes) is committed or rolled back as a whole. 

However, the counter value itself is using an eventual consistency mode. This is because even though you might have
incremented the value in a transaction (and gotten the modified value back), you can't be sure that the value hasn't
also been modified in another node. Eventually that other write will reach all the nodes in the cluster, but certain
failure modes can cause it to take quite a while. 

If you need to _rely_ on the counter value for operational reasons, you might want to consider either a property 
inside the document or use a compare exchange value, as we discussed in Chapter 2. Most usages of counters in 
RavenDB are resilient to the eventual consistency inherit to using them.

#### Deleting counters

Counters can be deleted using the Studio or the RavenDB Client API, as you can see in Listing 5.5. 

```{caption="Deleting a counter from a document" .cs}
using (var session = store.OpenSession())
{
    session.CountersFor("packages/393-A").Delete("DownloadsCounter");
    session.SaveChanges();
}
```

A counter deletion will be sent to the server when `SaveChanges` is called, as expected. One thing to note about the 
act of deleting a counter. Like all other operations on counters, we need to consider what will happen when there are
concurrent operations. One for deleting a counter and another to increment it. In this case, a lot depend on the actual
order of operations.

If the increment operation runs first, the counter will be deleted. However, if the delete happens to win the race, the
counter will be deleted, and then recreated by the increment operation. In a distributed setting, a delete on one node
and an update on another node will always resolve in favor of the update. 

If you need to delete counters, the usual way to do so it to ensure that in your application,
you aren't going to also try to write to them at the same time. 
But for the most part, counter deletions are relatively rare operation for typical applications. 

It is common to want to _reset_ a counter to zero, however. For example, if you are tracking services' status codes, 
you might want to reset the counter whenever a new version of the service has been deployed. This is usually better
to handle explicitly, as you can see in Listing 5.6.

```{caption="Resetting a counter value" .cs}
using (var session = store.OpenSession())
{
	var serviceCounters = session.CountersFor("services/2338-C");
	long failures = serviceCounters.Get("status/500") ?? 0;
    serviceCounters.Increment("status/500", -failures);
    session.SaveChanges();
}
```

In Listing 5.6, we reset the counter value to zero by getting the value and decrementing the current value. Other 
operations that might be modifying the counter at the same time can run concurrently without any issue.

Alternatively, you might have a different counter for each version of the service. So when you deploy a new version
your code will start incrementing the `status/3.2/500` counter and no longer modify the `status/3.1/500`
counter, which an now be safely deleted. This is a simple example of how you can ensure that there won't be concurrent
delete and increment operations on a counter.

#### Deleting a document with counters

A counter is attached to a document, and the deletion of a document will delete all the counters of a document. This 
might seems obvious, but I wanted to call it out explicitly. Deleting a document and then creating a new document
with the same name isn't going to restore the old counters.

In the same manner, an increment operation on a counter will create the counter if it doesn't already exists. However,
an increment operation on a counter of a _document_ that doesn't exists will fail. Counters can be created on the fly
but the documents that they belong to must already exist beforehand.

#### Patching counters

In Chapter 4, we talked about patching documents. The patching feature allow you to run a script that will run at 
the server side and modify documents based on your own logic. Patch operations also allow you to modify counters and
their values. 

For example, let's assume that we have an existing document with some properties that I want to turn into counters.
The code in Listing 5.7 shows how this can be done.

```{caption="Creating a counter from a document property, using patching" .cs}
using (var session = store.OpenSession())
{
	var script = @"
if (this.DownloadCount !== undefined){
	incrementCounter(this, "DownloadCount", 
		this.DownloadCount);
	delete this.DownloadCount;
}";
	session.Advanced.Defer(new PatchCommandData(
	    id: "packages/393-A",
	    changeVector: null,
	    patch: new PatchRequest
	    {
	        Script = script
	    }, patchIfMissing: null));
    session.SaveChanges();
}
```

The only items of interest in the patch in Listing 5.7 is the call to `incrementCounter`, which will create the counter
if it doesn't already exists. The rest of the code is identical to the patch operations that we already covered in 
Chapter 4. 

The patch API provides a few methods to work with counters:

* `incrementCounter(document, counterName, value);`
* `counter(document, counterName);`
* `deleteCounter(document, counterName);`

If you want to get the list of counters on a document, you can use the metadata property `@counters` to get the list
of all the counter names for a document.

You can use these methods and the `@counters` metadata property to programmatically modify documents and their counters
freely. 

#### Querying on counter values

Counters in RavenDB are meant for high frequency updates. Updating a counter value is something that is expected to happen
a _lot_. As such, RavenDB minimize the amount of work that is involved in updating a counter.

When querying, you can easily project a counter value: `from Services select counter(Requests)`. But querying on a counter
value is a different story. Consider the following query: `from Services where counter(Requests) > 1000`.
RavenDB ensures that queries are fast by answering them from the index, always. But in order to query using a counter's 
value, we need to actually _index_ the counter value.

That is a problem, and not just because the previous statement is confusing. It is a problem because if the counter value
is has a high frequency of change, we'll be constantly re-indexing. We'll discuss the details of indexing and querying in
RavenDB later in this book, on Part III. 

#### How counters are implemented

RavenDB is capable of handling concurrent and distributed updates to counters, always converging on the real value. But
_how_ is it able to do that? You don't need to know this in order to make use of counters in RavenDB, but it might be a 
good idea to skim through this section to understand what is going behind the scenes.

Internally, each counter has the following structure: Node Id, Value, Etag. To be rather 
more exact, we have this structure for a counter for every node that has made a write on the counter. 

In other words, let's assume that we have a three node cluster (nodes A,B and C) and a counter that was modified on nodes 
A and B. The state of this counter (on all the nodes in the cluster) is shown in Table 5.1.

| Node | Value | Etag |
|------|-------|------|
| A    | 4     | 17   |
| B    | 3     | 22   |

Table: Internal state of a counter value

From the information in Table 5.1, we know that the final value of the counter is 7. If we'll increment the counter by 3 
on node A, RavenDB will update its internal state to be similar to Table 5.2, for a total value of 10.

| Node | Value | Etag |
|------|-------|------|
| A    | 7     | 18   |
| B    | 3     | 22   |

Table: Internal state of a counter value, after updating on A

The `Node` and `Value` are fairly obvious, but what is this `Etag` doing there? The `Etag` is used to reliably resolve
distributed updates. Consider the case of two updates, happening at the exact same time, to nodes A and B. We decrement
the value by 2 on A and increment by 3 on B. At this point, both nodes A and B will notify node C (and each other) about
their updates. Table 5.3 shows how the update looks like from the point of view of node C.

| Node | Value | Etag |   | Node | Value | Etag |
|------|-------|------|---|------|-------|------|
| A    | 7     | 18   |   | A    | 5     | 19   |
| B    | 6     | 23   |   | B    | 3     | 22   |

Table: Inconsistent counter state after distributed modifications

When node C gets both update notifications, it needs to resolve them to a final value. It is able to do that using a 
simple process. For each entry in the counter values, find the maximum `ETag` for a particular node and use that value. 
In other words, we'll end up with Table 5.4.

| Node | Value | Etag |
|------|-------|------|
| A    | 5     | 19   |
| B    | 6     | 23   |

Table: Counter state after resolving conflicted values

For Node A, we selected the `Value` (5) with the highest `Etag` (19) and for node B we selected the `Value` (6) for the 
highest `Etag` (23). The final result is 11, which is the correct answer (10 - 2 + 3).

In other words, for counter, we keep track of the values for each node it was modified on. That node is the owner of that
value and the only one that can change it. And whenever that node's value changes, we increment the `Etag`. So if we have
to select between multiple values, simple finding the entry with highest `Etag` for a node ensures that this is the latest
value that we got from that node (directly or indirectly) and we may then proceed finding the final tally.

In practice, you should rarely concern yourself with these implementation details. You can get the raw values from RavenDB
using `counterRaw()` instead of `counter` in your queries, but that is there mostly to be able to show what is under the 
covers, not for any expectations that this will be used directly.

##### Overflow handling

Counter values in RavenDB have the following range: `-9,223,372,036,854,775,808 .. 9,223,372,036,854,775,807`. Attempts to 
increase the value over the maximum or below the minimum will *not* overflow. An error will be raised in this case.

An exception to this overflow behavior happens when you are running in a distributed mode and make concurrent 
changes to your counters on distinct nodes. Consider the case where a counter is set to `9,223,372,036,854,775,800`.
In other words, just 7 values from the maximum value possible for 64 bits integer.

At the same time, we are going to add `5` to this counter on two separate nodes. Each one of those operations is 
valid on its own, but together, they'll push the value over the maximum allowed. Because they are done on independnt
nodes, it is not possible to detect this in time. 

RavenDB will merge all those values and continue operations. The final value of the counter in this case will be set
to the maximum allowed to 64 bits integers. The reverse is true in the case of underflow, of course.

Note that the underlying values for each node are maintained, so decrementing the new value by `1` will not be
decrement the value. You'll need to decrement by `6` to see an actual change in the value. An example using 8 bits
integers will be easier to understand. Consider a a cluster with the state shown in Table 5.5.

| Node | Value |
|------|-------|
| A    | 59    |
| B    | 59    |
| C    |  6    |
|------|------ |
| Total| 124   |

Table: Distributed counter state, near the overflow limit

Adding `3` to both Node A and Node B at the same time will result in an overflow. The state of the counter after such
an addition and replication is shown in Table 5.6.

| Node | Value |
|------|-------|
| A    | 62    |
| B    | 62    |
| C    |  6    |
|------|------ |
| Total| 127   |


Table: Overflow on distributed counter peg the value to the maximum value

Remember, we are using an exmaple with 8 bits numbers here, so the maximum value is 127, even though adding 
all the numbers will give us 130. 

Decrementing the value by `1`, however, will not reduce the total to 126. Instead, we'll have:

| Node | Value |
|------|-------|
| A    | 62    |
| B    | 62    |
| C    |  5    |
|------|------ |
| Total| 127   |

Table: Changes are allowed on distributed overflown counter

We reduced Node C by one, but the value still overflows. We'll need to decrement the value three more times
to see the total value drops. 

RavenDB uses 64 bits signed integers for counters, so the likelihood of an actual overflow or underflow is very 
low. I'm including this infromation here for completion's sake and so you can plan even for unlikely events.

### Time Series

Time series, like counters, offer a dedicated way to store and query specific types of data inside RavenDB. As 
we previously mentioned, storing such data inside the document is not an optimal option. Unlike counters, which are
fairly simple, time series offer a lot more capabilities and features. We'll start by first understanding what is
time series data in the first place.

As the name suggest, time series data is intrisinctly tied to time. A good example of a time series is your heartrate. 
A single measurement of your heartrate isn't really that useful. What you typically want to see is your heartrate over
a period time. Each measurement is tied to the time it was taken on, and together, you can fit them all into a cohesive
picture.

Time series do not exist independently inside of RavenDB but are associated with documents (just like counters and attachments).
A document may have a number of time series and a time series may have any number of entries, represneting values over time.

Good examples of time series data are:

* Stock price for a company
* Heartrate of a person
* GPS location on a truck
* Temprature and humidity in a storehouse

The common thread across all of them is that you are usually more interested in how the value work over time, rather than
a specific value. Another issue that you have to take into consideration is that time series can be _large_. It isn't 
uncommon for a single time series to have millions of values. 

> **Time series terminology**
>
> It can be confusing to discuss time series, because a time series in casual speak may refer to all the values in the series
> or a particular value or range in it. To make things easier, I wanted to clearly define the terminology that I'm using
> in this chapter.
>
> * A `time series` is used to refer to a single time series on a document. 
> * A `time series entry` or `entry` are used interchangeably to refer to a single record `(time, tag, values)` 
>   inside a time series. 
> * `Values` or `value` are used interchangeably to refer to the _data_ that is being record. The heartrate, GPS location, etc.
> * `Timestamp` is used to refer to the time of a particular entry. Given how frequently we use the term `time` in this chapter
>   there was a need to have a word to unambiguously point to the time of a particular entry. `Timestamp` is always in UTC.
> * `Tag` is used to refer to a free text field that can be added to a time series entry.

RavenDB handles time series data in a similar manner as counters, by storing that in a dedicate model outside of the actual
documents. This allows us to apply a whole number of optimizations to the way we hold and process the data. But before we
dive too deeply into that, let's look into how time series are handled. We'll start with Figure 5.5, showing a document with
a single time series: `Location`.

![Document with time series data in the studio](./Ch05/img05.png)

Just like counters, a document with time series is flagged with that information and the list of all the time series for
a particular document is available in the `@timseries` array in the `@metadata` section of the document. To the side of
the document view in the studio, you can see some statistics about the time series. How many entries it contains
and the date range of the values. 

In this case, we are showing just a few entries, but we have tested RavenDB with time series cotaining hundreds of 
millions to billions of entries. RavenDB is able to handle them efficently and without fuss. See later in the chapter
where we discuss some of the implementation details that make such behavior possible. 

In the meantime, let's see what data we can store using time series. Figure 5.6 shows the actual time series entries.

![Time series entries for our office location over the years](./Ch05/img06.png)

There are a few interesting details to pay close attention to in FIgure 5.6. You can see that each entry in the table has
a time, a tag and the values. The time is fairly obvious, it is the time for the entry. And the values is also 
straightforward. Those are the lat/lng coordinates for our offices. Note that a single entry can contain more than a single 
value. What remains a mystery is the tag, which isn't so obvious. In this case, the tag is used to denote the city our 
offices is located in. We'll see how tags can be useful later on in this chapter.

Working with time series data from the client is very similar to counters, as you can see in Listing 5.8.

```{caption="Recording your heartrate" .cs}
using (var session = store.OpenSession())
{
    var watch = GetDevice("fitbit");

    (DateTime time, double bpm) = watch.GetLatest();

    var heartrate = session.TimeSeriesFor("users/oren", "Heartrate");

    heartrate.Append(timeToUniversalTime(), bpm, "watches/fitbit");

    session.SaveChanges();
}
```

The code in Listing 5.8 grabs some data from a device (a fitbit, in this case) and record it in the appropriate time series. 
There are a few things to note about the code in Listing 5.8. In order to work with time series, we use the `TimeSeriesFor()`
method, providing it with the document id and the time series name we want to work with. We can then `Append` an entry to 
the time series. 

To simplify matters, RavenDB uses UTC dates only for time series, you don't need to convert to and from the server's time zone.
When appending a value, you provide the time (in UTC), the value(s) and the tag. RavenDB supports 1 - 32 values per time 
series entry. Time series values are a double precision floating point numbers (or just `double` in your programming language
of choice). Note that the `NaN` value is excluded from the possible values (but `Infinity` is allowed). 

It is preferred, but not required, to append to the time series in a sequential fashion, as that result in the optimal layout
of data on disk. If you write to the time series out of order, RavenDB has to do a bit of extra work, but everything is going
to work as you expect it to. The granularity of the time series's timestamps is in millisecond. Writing to a value with a 
timestamp that already exists in the server will overwrite that value. 

In other words, if you are writing data from sensors or recording data on the fly, you are already going to be doing 
the Right Thing, as far as RavenDB is concerned. Always appending data at the end and appending data in a sequential manner.
If you don't match that behavior, if you need to write out of order or update values, that is fine. RavenDB will just make 
things work for you. 

In the same manner, RavenDB will work best when all the entries in a time series have the same number of values. However,
you are free to have entries with different number of values, if that make sense for your scenario. The number of values
of a time series entry is in the range of 1 to 32. You can treat these values together or as independent values. 

For example, when recording GPS coordinates, there is little sense in splitting the lat and lng values. You can't really use
just one of them. The same is the case when you record blood pressure measurements, with systolic and asystolic values that
go together with one another. On the other hand, if you are recording currency exchange rates, you might record every minute
the exchange rate of multiple independent currencies. In such a case, you can focus on just one of those values, insetad of
trying to keep track of all of them.

#### Tags in time series entries

You might have noticed the notion of a `tag` that keeps popping up when discussing time series data in RavenDB. What is
that about?

A time series entry is composed of a timestamp and a set of values that represent measurements taken at the specified time.
In a perfect world, this would be all that we need to deal with the data. Indeed, a lot of complexities that are usually
associated with time series are handled by the assoication of time series to documents. We'll touch on this more later
in this chapter, when we'll talk about modeling concerns for time series.

Consider the case of heartrate monitoring. There are many ways to monitor one's heartrate. For example, I'm currently 
wearing one such device, a FitBit. At some other time, I may wear an Apple's Watch or be hooked up to a medical device
during a routine checkup. 

In other words, even though the values go to the same place and have roughly the same meaning, there is a lot of value
in recording additional information about the recording itself. If I'm using a consumer device or a hospital-grade sytem
_matters_, and we should be able to record that. That is where tags come into play. 

Tags allow you to provide additional meta information about the recorded values. Typically, this is some information about
how the information was achieved. When recording GPS data, we'll record the device model that was used to get the 
coordinates. If I'm keeping track of multiple exchanges watch for currency flacutations, I might want to record which 
exchange a particular rate applies to, etc.

Tags allow you to tag a single entry with a string (up to 255 bytes). Because the size of the data is limited, you'll 
typically add a document id for any additional information. For example, in the GPS tracking example, you'll store the
device's document id as a tag, and then have a document describing the capabilities of the device. 

That raise a question, why would we create a document for each time series entry? The whole _point_ of time series is to
allow you to store vast amount of data efficently. If we create a document per entry, that isn't very efficent, is it?
The answer is that is that you aren't going to have a document per time series entry. Indeed, RavenDB optimize heavily
toward _repeating_ tags values.

The idea is that the time series entries are going to repeat the tag value frequently. Using the heartrate example, most
of the time, you are going to get values from a single device. In Listing 5.8, the tag was `watches/fitbit`, for example,
and it is safe to assume that most of the entries are going to share that tag. Changing the tag isn't an issue, either, 
because then you are going to repeat the new tag often.

> **Tags are metadata _pointers_ about the entry**
>
> It's easiest to think about tags as a way to add a reference for additional infromation about the entry. A document id
> is a great example of how you can store additional data about your time series entries. 
>
> RavenDB anticipates such usage and have several features around querying of time series that assume that you can fetch
> addtional information about a specific entry from the document referenced by the entry's tag.

With the current exchange rate example, you'll tag each entry with the document id of the exchange we got the values from.
In this case, we will have interleaved tags. Each time that we append an entry to the time series, it may come from another
exchange. But in that case, you'll have a (small) set of values that are repeating, which is also something that RavenDB
is well prepared for.

This is a heavily optimized convention, not a requirement. You can chose to omit the tag entirely, if it make no sense in
your scenario. There is nothing to be concerned about by omitting the tags. On the other hand, adding many distinct 
tag values will _work_, but prevent RavenDB from optimizing storage usage properly. 
See later in the chapter when I discuss the implementation details of time series.


#### Modeling concerns with time series

#### Rollups

#### Time series implementation in depth