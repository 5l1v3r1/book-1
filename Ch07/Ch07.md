
## Scaling distributed work RavenDB

[Distributed Deep Dive]:(#clustering-deep-dive)

In the previous chapter, we went over how RavenDB clusters and database groups work, we looked at the nitty gritty details, such as conflicts
and change vectors and how a cluster can handle failover and recovery. But we haven't actually talked about how to actually make use of a cluster.
This is primarily what we'll cover in this chapter. How to properly utilize your RavenDB cluster to best effect.

We'll cover how to grow your cluster to include a large number of nodes and how to host a _lot_ of databases in the clsuter, how we can automatically
have the cluster adjust the nodes a database reside on to ensure a minimum number of replicas and how we can deploy RavenDB in a geo distributed 
environment.

But first, we need to go back a bit and discuss the distributed mechanims in RavenDB, the cluster and the database group. The separation RavenDB makes between 
the cluster and the database group can be artifical. If you are running a single database on all your nodes, you usually
will not make any distinction between the cluster as a whole and the database group. This distinction starts to become a lot more important if you are working
in a system that utilizes many databases.

The simplest example for such a system is a micro service architecture. Each micro service in your system have its own database group that is running on the 
cluster, and you can define the number of nodes each database group will run on. This tend to be easier to manage, deploy and work with then having a separate
cluster per micro service. 

Other examples where you'll have multiple databases is for multi tenancy, where each tenant gets their own separate database. This make it very easy to deal
with tenant separation and you can adjust the number of nodes per tenant easily. This approach will also allow you to scale your system easily. As you have 
more tenants, you can just add more machines to the cluster and spread the load among them. 

That said, note that there is a certain cost for running each database instance, and that it is usually easier for RavenDB to have a single large database then
_many_ small ones. The general rule of thumb is that you shouldn't host more than a hundred or so active databases per machine.

### Growing your cluster

RavenDB is using Raft as the underlying consensus protocol for managing the cluster. The [Raft Paper](https://raft.github.io/raft.pdf) is a truly impressive 
reading, mostly because the paper manage to make one of the hardest tasks in distributed programming _understandable_. I highly recommend reading it even if
you never intend to dig into the details of how RavenDB or other distributed system does their magic. 

The simplest way to explain how it works is that the cluster make decisions based on majority confirmation. That does great injustice to both the algorithm and
the paper, but it simplify things and allow us to reason about them without deviating _too_ much from what is really going on. Majority confirmation is defined
as having a particular value on `N/2+1` of the nodes, using integer math and assuming that `N` is the number of nodes. In other words, if your cluster size is
3, then a majority would be 2 and any value that was confirmed by any two nodes is considerred committed.

Table 7.1 shows the majority for several common cluster size. Note that even numbers have the same majority as the odd number preceding them. Because of that,
you'll typically have an odd number of nodes in your cluster. 

| Cluster size | Majority |
|--------------|----------|
|            2 |        2 |
|            3 |        2 |
|            4 |        3 |
|            5 |        3 |
|            7 |        4 |
|            9 |        5 |
|           15 |        8 |
|           21 |       11 |
|           51 |       26 |

Table: Majories for different sized cluster

This majority behavior has a few very interesting implications that you need to consider. First, and quite obvious, if we have a failure condition that 
took out more than half of our cluster, the cluster as a whole will not be able to make any decisions (even while individial database instances will operate
normally). In a cluster of 5 nodes, if there aren't any 3 nodes that can communicate with each other, there is no way to reach any decision. 

On the other hand, the more nodes there are in your cluster, the more network traffic you need to make to reach any decision. In patalogical cases, such as a 
cluster size of 51, you'll need to contact at least 26 servers to reach any decision. That is going to impose a high latency requirement on anything that 
the cluster is doing. 

In practice, you very rarely grow the cluster beyond seven members or so. The cost of doing that is usually too high. At that point, you will either setup 
multiple independent clusters or use a different method. The cluster size we mentioned so far is for voting members in the cluster, but the cluster doesn't
have to contain only voting members. We can just add nodes to the cluster as watchers.

These nodes do not take part in the majority calculations and are only there to watch what is going on in the cluster. As far as RavenDB is concerned, they are
full blown members in the cluster, they can be assigned databases and work to be done, but we aren't going to include them in the hot path of making decisions 
in the cluster.

Using this approach, you can decide that three or five nodes in your cluster are the voting members and all the rest are just watchers. This gives us the ability to 
make decisions with a majority of only three nodes while the actual size of the cluster can be much higher. Of course, if a majority of the the voting members of
the cluster are unable to talk to one another (because they are down, the network failed, etc) then the cluster as a whole will not be available. 

> **What are cluster operations?**
>
> We have talked about cluster being down a lot, actually a lot more then most clusters _are_ down. A cluster being down means that database operations continue
> normally for databases, but we can't perform any cluster operation. What are all those cluster operations?
>
> Basically, anything that requires us to coordinate between multiple nodes is a cluster operation. A non exhuastive list^[The full list can be found in the online
> documentation] include creating and deleting databases, creating and deleting indexes and transformers, handling subscriptions and ETL processes and completing a 
> backup^[Backups _will_ happen on their regular schedule when the cluster is down, but they fail to be reported to the cluster and may run again after the clsuter
> recovered.].
>
> In all those cases, those are operations that we need a majority in the cluster to proccess. The underlying logic behind all of those operations is that they are
> all things that aren't generally user facing, so even in such an event, you'll be able to continue serving requests and operate normally as far as the external
> world is concerned while your operations are bringing up the failed nodes.

Figure 7.1 shows a cluster using three member nodes and two watchers. Node E is the leader and it is managing all of the nodes. Creating a database on this cluster
will cause it to allocate database instances to both member nodes and watchers node, but the cluster leaders can only be nodes A, B or E. If two of them are down
then the cluster as a whole is also down and you'll not be able to perform cluster operations (but your databases will function normally otherwise.)

![A cluster with members and watchers](./Ch07/img01.png)

Given that a cluster being unavailable doesn't usually impact ongoing database operations, the actual topology at scale is something that the operations team
need to consider. A single large cluster is usually easier to manage and the cluster can add as many watchers as you need to handle the load you are going to 
put on it. The databases themselves do not care what node they run on, whetever it is a voting member or just a watcher. And the cluster can manage database 
instance assignment across all machines with ease. 

### Mutliple datacenters and geo distribution

It is easy to reason about RavenDB's distributed behavior when you are running on the local network or in the same data center, but what about when you have 
multiple data centers, and what about when you have geo distributed data centers? Those are important considerations for the architecture of the system.
Because there are so many possible deployment options, I'm going to use AWS as the canonical example, simply because there is so much information about it
and you should be able to adapt the advice here to your need easily enough even if you aren't using AWS.

Inside the same availability zone (same data center) in Amazon, you can expect sub 1 ms ping times. Between two availability zones in the same region (separate
data centers^[Note, this assume that the connection between those data centers does not go over the public internet but dedicated lines. If the connection between
the data centers is over the public internet, expect higher latency and more variance in the timings.] that are very close by) you'll typically see ping times 
that are in the single digit millisecond range. 

The default configuration for the RavenDB cluster is each node expects to get a heartbeat from the cluster leader every 300 ms. When running in the same data
center, that is typically not a problem unless there is a failure of the leader (or the network), in which case the cluster as a whole will select a new leader.
However, what happens when we start talking about geo distributed data centers? Let's talk about the datacenters in Table 7.2. 


|  Data center  |      Tag       |
|---------------|----------------|
| N. Virginia   | us-east-1      |
| Ohio          | us-east-2      |
| N. California | us-west-1      |
| London        | eu-west-2      |
| Singapore     | ap-southeast-1 |

Table: A few AWS datacenters and their locations

Ping times^[The ping times between these data centers were taken from [https://www.cloudping.co/](https://www.cloudping.co/).] between those datacenters are quite
different. For example, N. Virginia to Ohio is 30 ms, N. Virginia to N. California is already at around 70 ms. From N. California to London is twice that at 140ms
and Singapore to N. Virginia clocks at 260 ms.

Given that the default configuration calls for an election if we didn't hear from the leader in 300 ms, it is clear that you can't just throw a cluster that is 
going to have a node each in N. Virginia, Singapore and London. The network latency alone would mean that we'll be unable to proceed in most cases. However,
that is just the default configuration and easily changed. The reason that I'm dedicating so much time to talking about latency here is that it has a lot of 
affect on your systems that you need to consider.

If we have the need to run in multiple data centers, or even in geo distributed data centers, we need to consider the latency between the datacenters and what it
means for your application. There are two options that we should consider, the first is having a datacenter spanning cluster and the second is to have a cluster
per datacenter.

#### Single cluster, multiple datacenters

When you have a single cluster spanning multiple datacenters you need to consider the expected latency and behavior. The actual configuration of the cluster
timeout is easy to set (the configuration option is `Cluster.ElectionTimeoutInMs`, defaulting to 300 ms), but that is the least interesting thing about this 
scenario.

When running in a geo distributed cluster, we need to consider what are the various operations that we use. The cluster timeout is merely the maximum amount of time
that the nodes will wait for a notification from the leader before deciding that there isn't a leader and that an election needs to be held. If there is work that
the cluster needs to do, it will not wait for the timeout to happen. Instead, it will always execute it as fast as it can.

On the other hand, an excessively high timeout value will mean that the cluster will take longer to detect that there is a failed leader and recover from that. In 
general, the cluster will typically recover from a failed node in up to to three times the timeout value so that needs to be taken into account. On the WAN, I'll 
suggest you raise the timeout to 3 - 5 seconds and see how stable that is for your environment. A lot of that depends on the quality of the communication between
the various nodes in your cluster. 

We talked a lot so far about the cluster and the effect of latency on the cluster, but most of the time we are going to operate directly with the database, not the 
cluster, so how does running in a geo distributed environment affect the database replication?

The answer is that it generally doesn't. The database level replication was designed for WAN, and doesn't have any hard timeouts like the cluster level. The cluster
needs to know that there is an active leader, because if there isn't, the node needs to step up and suggest itself as the next leader. But at the database level all
the nodes are equal, and any distruption in the communincation between the nodes is handled by merging the data from all the nodes at a later point in time, resolving
any conflicts that may have occured. This means that a database group is much easier to deploy in a geo distributed environment with high latency, because the 
nodes are fine with delays. 

> **Database instance distribution in the multi datacenter cluster**
>
> RavenDB assumes that all nodes in a cluster are roughly equal to one another, and when you create a new database it will assign instances of this database to nodes
> in the cluster, regardless of where they are located. If you are running in a multi datacenter cluster, you probably want to explicitly state which nodes this
> database will reside on, so you can ensure that they are properly divided between the different data centers.

Another consideration that you have to take into account is that there are also the clients. A client running on the London datacenter that connects to the Singapore
node for all queries is going to suffer. By default, RavenDB assumes that all nodes are equal, and the cluster will arbitrarily choose a node in the database 
topology that we'll typically work with. 

In the previous chapter, we talked about load balancing and how we can ask RavenDB to handle that for us automatically. One of the options available for us there is
`FastestNode`. This option will make each client determine which node (or nodes) are the fastest as far as it is concerned and access them according to speed. This
mode, in a geo distributed configuration, will result in each client talking to the node closest to it. 
That is usually the best deployment option for such an environment, because you are both geo distributed and able to access a local instance at LAN speeds. 

There is an issue that you need to handle, when your system is compose of parts far enough apart that can take hundreds of milliseconds just to send a packet back 
and forth there is the issue of consistency. If you are writing a document in one area it is not guaranteed that you'll see the write in another area. In fact, you'll
always have to wait until that write has been replicated.

We talked about write assruances and `WaitForReplicationAfterSaveChanges` in the previous chapter, but it is very relevant here. After you make write with the 
`FastestNode` option, the next session you open might access a different node. In order to ensure that the next request rom the user will be able to read the write
the user just made, you need to call `WaitForReplicationAfterSaveChanges`. Alternatively, if this is a write where a short delay in replicating to all the other 
nodes is acceptable you can skip it and avoid the need to get confirmation across the entire geo distributed cluster.

#### Multiple clusters, multiple datacenters

A single cluster spread over mulitple datacenters can be convenient for the operations team, since there is just this one cluster to manage everything with, but it
can also create headaches. For example, if we have 2 nodes in London and one node in N. Virginia, our leader will tend to always be based in London. Any outage 
between the two datacenters will leave the cluster fully functioning in London and unable to complete anything in N. Virginia (since it can't reach the other side).

Another problem is that failover _between_ datacenters is not something you'll want to do. You might want to fail _to_ another datacenter but failing a web app from
the N. Virginia datacenter all the way to the London datacenter impose a very high latency. If a page is making just 8 database requests, is it going to take over a
second to answer render a single page, and that is just calculating the network roundtrip costs. In such cases, it is often preferable to send the web traffic 
directly to the London datacenter until the N. Virginia datacenter is fully up again.

In such a scenario, having a single cluster will actually work against us. The problem is that the client API will automatically failover to any available node, but
in this case, we don't want that. We cannot tell the client not to failover to nodes in our cluster, that doesn't make sense. The appropriate way to handle this is 
to create separate clusters, one in each data center. In this manner, each datacenter's cluster is independent and manages just its own nodes. The client API in each
datacenter is configured to point to the nodes in that datacenter only. 

In this case, because failover stops at the cluster boundary, so there will be no failover between datacenters. But we still need to deal with a tough problem, how 
are we going to handle sharing the data between the separate clusters? 

#### Sharing data between clusters

A RavenDB cluster is a standalone unit, it manages itself and doesn't concern itself much with the outside world. There are situations, however, where you want to
have data shared between multiple clusters. This can happen if you want an offsite replica of all your data or if you have decided to have different clusters in 
each data center rather than a single cross data center cluster.

> **A replica isn't a backup**
>
> It is tempting to think that an offsite replica is also going to serve as the backup and not pay careful attention to the backup / restore portion of your
> database strategy. That would be a mistake. RavenDB's External Replication suppoert means that you get an offsite replica, but it doesn't provide good
> answers to a lot of backup scenarios. For example, protecting you from an accidetnal collection delete or "what was the state of the system in 9:03 AM last Friday?"
>
> An offsite replica gives you an offsite live copy of the data, which is very useful if you need to shift operations to a secondary data center, but it isn't
> going to allow you to skimp on backups. We cover backups (and restoring databases) in [Disaster Recovery and Plan B (for Backups)](#disaster-recovery).

Setting up replication between clusters can be done quite easily, because RavenDB make a strong distinction between cluster and database group interactions. 
In this case, this allows us to definea replication target that is not part of the cluster itself. We can do that in the database by going to `Settings` and 
then `Manage Ongoing Tasks` and adding an `External Replication` task. You'll need to provide the url and database name for the destination, and then save the
new replication. 
If you don't have an additional cluster to test this on, you can specify one of your own nodes and create a _separate_ database to replicate to.

> **Replicating to the same cluster**
>
> On the face of it, it seems very strange that we can setup an external replication from the cluster back to itself. Why make it an external replication, then?
> This can be useful if you want a copy of the data that wouldn't be a failover target for the clients. It may be an offsite backup or just a dedicated database
> that is setup so it will do some work (such as run ETL process). 

Ongoing tasks in general is quite interesting, and we'll discuss that at length in the next section. For now, we'll focus on what the External Replication feature
and what it means for us. Once we have finished configuring it, the cluster will assign one of the database group nodes to keep that replica up to date at all 
times.

It is important to remember that at the database level we treat it as just another destination, the cluster is _not_ managing it. That means that cluster 
level behaviors, such as defining conflict resolvers, failover for the client or index replication are _not_ send over. An External Replica is just that, 
external. You can configure both the source cluster and the destiation replica in the same manner, of course, but there is nothing that forces you to do so. In fact, 
the other common reason why you will want to setup an External Replica is to have _different_ configuration.

A good example of this is when you want to have expensive indexes and only run them on a particular machine. Maybe you need to run expensive analytics or to do
certain work on a specific location. Using External Replication gives you the ability to control the flow of the data without also dictating how it is going to
be processed. 

What would it take to have an offsite replica for our cluster? That is quite easy. In the studio, go into `Settings` and then to `Manage ongoing tasks` and click
on `Add`. Choose `External Replication` and fill the URL and database name, and that is pretty much it. The cluster will assign that replication target
to one of the database instances in the database group and it will immediately start replicating the data to the target.

It is important to understand that for all intents and purposes, this is just the same replication that happens between different nodes in the same cluster. The
nodes don't know (or care) that this particular replication target it no in their cluster. This is quite important, because it means that you can use all the 
replication features, including optimistic concurrency across disparate, geo distributed, clusters.

External replication between two clusters will detect conflicts in editing the same documents in separate clusters and will resolve it according to each cluster
conflict resolution policy.^[The conflict resolution will then flow to the other cluster as well, so it is _highly_ recommended that you'll have the same policy
configuration on both clusters unless you have a specific reason not to, such as one way replication or meaningful difference in the tasks that the different
clusters perform in your system.]
Figure 7.2 shows the result of a cluster that has defined several external replication from the cluster for various purposes.

![Several external replication tasks and their responsible node](./Ch07/img02.png)

Also in Figure 7.2 you can see that the responsible node portion has been emphasised. In it you can see the node tag responsible for keeping each replication
target up to date. You can also see that the cluster has assigned each external replication task to a separate node.^[The cluster will make that determination
on its own, and it may not always perfectly distribute the work among the nodes in this fashion. Overall, however, the work will be distributed among all the
nodes to create a rough equality of work]. 
We haven't discussed it yet, but that is one of the more important roles of the cluster, deciding what work goes where. 

### Ongoing tasks and work distribution

The cluster as we know it so far isn't really smart. It give us the ability to distribute configuration, such as what databases goes where, what indexes are 
defined, etc. But it doesn't _do_ much. This is actually quite far from the way things are. This is because we have focused specifically on the flow of data 
inside a database group, rather then the flow of _work_. 

What does it mean, to have work assigned to a database group? The simplest example is the one we just talked about, external replication. If we have three nodes 
in this database group, which node is going to update the External Replica? We don't want to have all three nodes do that, there is no real point in doing so, 
and it can cause unnecessary network traffic. Instead, the cluster will assign this work to one of the database instances, which will be responsible for keeping
the External Replica up to date. 

Another example is hourly incremental backup of our data as well as a full backup on a weekly basis. We don't want to have this backup run on all three nodes at 
the same time, leaving aside the fact that this will increase the load on the system across the board, we don't really have anything to do with triplicate 
backups of the same data. This is where the work assignment portion of the cluster come into play. 

Whenever there is a task for a database group to do, the cluster will decide which node will actually be responsible for it. That seems pretty easy, but there is
actually a bit more to the story. Just assigning work is easy, but the cluster is also watching the nodes and checking how healthy they are. If a node is down, 
then the cluster will reassign the work to another node for the duration. 

In the case of a backup, if the node that is responsible for the backup is down when the backup is scheduled, another will shoulder the load and make sure that 
you don't have any gaps in your backups. In the case of External Replication another node will transparently take over keeping the External Replica up to date 
with all the changes that happened in the database group. 

Another type of work in the cluster that we already talked about in this book is subscriptions. The cluster will divide all the subscriptions between the various
nodes in the database group and reassign them on failure without your code needing to change anything (or even typically even be aware of that). Other types of
work that we can define for the database group include ETL processes, which are covered in the next chapter. 

An fun way to experiment with this is to create some work in your cluster (a few external replications or subscriptions would do just fine) and then close one 
of the nodes.
You'll be able to see the cluster recognize the failed node and move work around to the surviving ones. A nice demo to give you a taste of RavenDB's failover
capabilities is to have a client writing to the database and a subscription open when you close the node (make sure to close the node that the subscription
is assigned to). You shouldn't really notice anything happening from the outside. Both subscriptions and clients will silently move to another node and 
everything will Just Work. You can monitor all of the work in the database group from the `Ongoing Tasks` page as you run this experiment.

But you aren't the only one who is watching the state of the cluster, there is another entity in play here, the supervisor, and it is the one that is responsible
for making all those separate pieces cooperate seemlessly in the face of error conditions.

### The ever watching supervisor

The cluster is continously measuring the health of each node in the cluster, using a component known as the supervisor^[I always imagine it in bright neon green
tights and a cape, flying around spouting cliches as it keeps everything in order.]. The supervisor will detect any errors in the cluster, react to a failed node
by reasssigning work and in general keep everything running.

This is important enough to mention here and not in the Operations portion of the book because the Supervisor also gives you a wealth of information about the 
state of the different nodes and database instances that are running on them. In addition to just reassign work to surviving nodes, it is also responsible for 
its most important roles is the promotion and demotion of database instances.

Given that RavenDB is a distributed database and not a military organization, what does it means, promotions and demontions? Consider the case of a database 
group that has two database instances. We want to increase the number of replicas so we add a new node to the database group. The process is pretty easy, all we 
need to do is to click on `Manage group` in the Studio and add the new node. 

On large databases, the process of adding a new replica can take a while. During that process, the newly added node isn't really part of the group. It cannot 
take over work in the group (we certainly don't want its backup until it is completely caught up, for example) and we don't want to failover clients to it 
(since it doesn't have the full data yet). Because of this, when you add a new node to a database group, it isn't added as a full fledged member, instead, it is
added as a promotable instance. 

What does it means, promotable? It means that it cannot be assigned work for the database group, that it cannot be failed over to. In fact, it _is_ work for the
database group, since one of the full members is going to have to start pushing data into this new node until it is fully up to date. This goes on until the 
supervisor can confirm that the new node is caught up with the state of the database group and that it finished indexing all the data that we sent to it. At 
this point, the supervisor will promote the node into a full member in the database group, work will be assigned to it and clients will consider as a 
failover target.

That works when we are talking about new nodes, but what happens when we have existing node fail? If a member node fail, we don't want to go back into the 
usual rotation as soon as it recovers, we want it to pull all the changes that happened in the meantime from the other members in the database group. Because
of that, the supervisor has the notion of sending a node to rehab.

A node in rehab isn't a full member of the cluster, it behaves exactly like a promotable node, for the most part.
Like a promotable node, one of the other members in the database group will connect to it and update the 
recovered node until it is fully up to date, at which point the supervisor will promote it to full member again.

The only important distinction between a rehab node and a promotable node is what happens when all the members in a database group are down. This is only 
relevant in pathological cascading failures scenarios.
Consider a cluster of 3 nodes with a database residing on nodes A and B. First, we have node B failing for some reason (perhaps the operations team took it
down to apply patches). The supervisor will detect that and move node B to the rehab group. Node A will assume all duties that were previously assigned to 
node B. 

//TODO: image of a database graph

When node B comes back up, node A will send it all the updates that it missed. However, if node A is also failing at this point (the operations team now 
rebooting that node, without letting it time to get node B fully up to date) we are in somewhat of a pickle. On the one hand, we don't have any working
members to failover to. On the other hand, node B is functioning, even though it is currently in rehab. 

At this point, when there are no more active members in the database group, the supervisor will rehabilitate an active node from the rehab group and mark
it as a full member in the database group, restoring functionality to that database.
This isn't ideal, of course, because it might be missing writes that happened to node A and hasn't been replicaetd yet, but it is better then losing access
to the database completely.

> **Keep calm and serve requests**
>
> You might have noticed that the scenario requiring us to rehabilitate a node in rehab is most easily explained via an operator error. Though rare, such things
> happen on a fairly regular basis, [about a quarter of production failures](https://journal.uptimeinstitute.com/data-center-outages-incidents-industry-transparency/)
> are the result of a human error.
> 
> One of the primary goals of RavenDB is that the database should always be up and responding. That means that we do automatic failover on the client and will
> always accept writes as long as there is a single node functioning. 
> The idea is that we want to free the operations team from routine tasks that can be handled automatically. For the same reason, RavenDB utilize the supervisor
> to automatically and transparently handle failures for you. Having taken that role upon ourselves, we strive to make as complete a job of it as possible.
>
> Features such as sending nodes to rehab and rehabilitating nodes are part of that, they are there to handle rare edge cases in production and to avoid getting
> into situations where a temporary failure become a permenant one.
>
> That said, the operations team has a critical role in keeping RavenDB running. The supervisor can only do what it was told to do, and there are too many variables
> in real production systems to account for them all. The design fo RavenDB takes that into account and allow you to override the supervisor decisions to fit your
> needs. 
> We'll cover THS supervisor with a lot more detail in the ["Prouction Deployments"](#production-deployments) chapter. 


The clients are also aware of the nodes in rehab, and if they are unable to talk to any of the members, they will try to talk to the nodes in rehab as a last ditch
effort before returning an error to the caller. A major reason why we run this logic on both the clients and the supervisor is that this allows us to respond to 
errors in a distributed fashion in realtime, without having to wait for the supervisor to find the failure and propogate the information about it throughout the clsuter
and the clients.

Using demotions and promotions as needed, the supervisor is able to communicate to clients (and the rest of the cluster) which are the preferred nodes for a 
particular database group. Note that a failure doesn't have to be just a down node, something as simple as running out of disk space can also cause a database
on a node to fail and send it to rehab until that situation is fixed.

The supervisor is always running on the leader node, and it operates on the cluster level. In other words, it require consensus to operate. This protect us
from a rouge supervisor deciding that all nodes are unresponsive and taking them all down. But as long as it has the votes of a majority of the cluster, the
supervisor is the authority about who is up or down in the cluster and clients will avoid talking to nodes that the supervisor cannot talk to, even if they
can reach them.

### Ensuring minimum number of replicas

When you create a database, you also specify the number of replicas for that database. This is used by the cluster to decide on how many database instance to create
for this database group. One of the roles of the supervisor is to make sure that this value is maintained over time. What do I mean?

Consider a five node cluster and a database that was created with a replication factor of 3. The cluster assigned this database to nodes A, B and E. After a while
the supervisor notices that node E is down. It move it to the rehab program and hope that it will recover. However, after a while (the default value is 15 minutes)
the supervisor decides that it cannot assume that node E will come up any time soon and it need to take action to ensure that we have enough replicas for the data
in the database.

At this point, the supervisor will create another database instance on another node (C or D, in this case) and add it to the database group as promotable. At that
point, the database group will look like Figure 7.?.

//TODO: Figure of 5 nodes cluster and 2 db nodes up, 1 rehab, 1 promotable.

Two of the nodes in the database group are members in full health (A & B), we have node E in rehab and currently not responding and the new node D that was added as
promotable. At this point, we have a race between node D getting all the data from the other members in the database group and becoming a full member and node E 
recovering and getting up to speed with all the changes it missed.

Either way, one of them will cross the finish line first, at which point we'll have three full replicas of the data in the database. At this point, the supervisor will
delete the extra copy that is now no longer needed. If node E is down for long enough, by the time it is up it will no longer be a part of the database group topology
and the cluster will tell it to delete the copy it currently holds. 
On the other hand, if node E recovers in time and catches up to the rest of the members before node D is ready, the supervisor will promote node E to the database group
members again and let node D know that it needs to delete the now extraneous copy. 

> **Rebalancing of data after recovery is at the hands of the admin**
>
> In the scenario outlined above, if node E was down long enough that we removed the database from it and moved it to node D, what would happen when node E recovers?
> At that point, all of its database has been redistributed in the cluster, and it is effectively an empty node. 
> RavenDB will _not_ start moving databases back to node E on its own and require the operations team to instruct it to do so. Why is that?
>
> The supervisor has acted to ensure that the number of replicas for a database is maintained, which is why we allow it to just create a new replica on the fly and move the
> database instance between nodes. However, we don't know what the state of node E is at this point, it may fail again. Even if it is here to stay, the act of moving a
> database between node can be pretty expensive.
>
> It requires a lot of disk and network I/O and that isn't something that we want to just do on the fly. We only do that automatically to ensure that we keep the minimum
> number of copies that we require. Restoring the state after the incident is over is at the hands of the operations team, which can move the database between the nodes
> at their own schedule. 

The logic behind the supervisor behavior is that a node is allowed to fail for a short amount time (network partition, reboot for patching, etc) but if it is gone for a 
long time, then we need to take action if it won't be coming back up. It is important to take this behavior into account during maintenance, you need to let the 
supervisor know that it shouldn't take actions right now and that an actual operator is handling things and it shouldn't get in the way.

Because of the impact of the supervisor decisions, it will generate an alert for the operations team to review whenever it make a big decision such as moving a database
between nodes. Those alerts can be reviewed in the `Notifications Center`. That, and other topics relating primarily to operations are covered in more depth in the
["Prouction Deployments"](#production-deployments) chapter.

### Summary

We started this chapter by talking about how we can grow our RavenDB cluster. After a certain size, it doesn't make sense to add more members to a cluster and we
should add watchers, instead. Those are non voting nodes in the cluster that are still fully managed by it. The advantage is that we have a single cluster and only 
a single thing to manage, but we don't have to suffer from very large majorities and the latencies that they can incure.

From a single large cluster we looked at what it would take to work with RavenDB with a geo distributed environment. We look at the implications of that and the pros 
and cons of having a single cluster span multiple geo distributed datacenters or having a separate cluster per datacenter. If we have separate clusters, we need to
share data between them and External Replication is the answer to that. This allows you to tie separate clusters together by replicating all changes to another 
database, not necessarily on the same cluster.

This is a good option for offsite replica and to tie separate clusters together, but it also demarcate a very clear line between the databases instances that are in 
the same group and an External Replication target. Databases instances in the same group share work assignments between them, clients can failover from one instance
to another in the same group transparenely, etc. With External Replication, the only thing that happens is that the data is flowing to the replication target, it 
isn't considered to be a part of the database group at all.

We looked into the kind of work you can assign to databases such as backups and subscriptions or filling up promotables or in rehab nodes to allow them to catch up
to the rest of the nodes in the cluster. The supervisor is responsible for assigning the work and it can reasign work if a node failed. 

The supervisor has a critical role in ensuring the proper functioning of a RavenDB cluster. In addition to monitoring the health of the cluster is is also capable
of taking action if there are problems. A failed node will be moved to rehab until it is feeling better and a node that is down for long enough will be automatically
replaced by the supervisor. 

This was anything but a trivial chapter and I tried to focus on the high level concepts more then the nitty gritty details. The purpose of this chapter is to get you
to understand how RavenDB operates in a distributed envrionment, it is explicitly isn't about telling you how to actually run it in such an envrionment. That is handled
in the ["Prouction Deployments"](#production-deployments) chapter. 

Beyond just setting up a cluster, you also need to know how to monitor and manage your systems, and that is covered in a chapter dedicated just for that,
[Statistics, Monitoring and Insight](#monitoring). We'll also talk a abit more about the implementation details that I intentionally skipped here, because the
operations team need to understand what is going on exactly, while this chapter was about the overall concept.

In the next chapter, we'll talk about how we can integrate with other systems in your organization and introduce the concept of ETL^[Extract, Transform, Load], which allow
RavenDB to write data to external source automatically.