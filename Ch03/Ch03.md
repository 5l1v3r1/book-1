
# Document Modeling

Modeling your data is important, crucially so. This is because RavenDB, and any other database, really need you to understand 
how it is actually storing information, what are the features that it has available for you to utilize and what impact 
different modeling decisions will have on your data, the amount of work the database needs to do, etc.

If you get it wrong, you may be forcing the database to do expnonential amount of additional work. On the other hand, if you 
play for the database strengths, you can get a robust and easy to build system. So, overall, no pressure whatsoever.

Relational based modeling is so frequently encountered that is most cases you don't even see people talk about the relational
part, they just consider that as simple "data modeling". But when you try to apply a relational modeling solution to a non 
relational system, the end result is usually... suboptimal.

> **Documents are not flat**
>
> Documents, unlike a row in a relational database, are not flat. You are not limited to just storing keys and values. Instead, 
> you can store complex object graphs as a single document. That includes arrays, dictionaries and trees. Unlike a relational
> database, where a row can only contain simple values and more complex data structures need to be stored as relations,
> you donâ€™t need to work hard to map your data into a document database.
>
> That give you a major advantage and simplify a lot of the common tasks, as you'll see in this chapter. 

The problem is that this is extremely well entrenched behavior, to the point where most people don't even realize that they are
making choices and decisions based on what would work best for a relational database. So the first section of this chapter is 
going to deal with how to get away from the relational mindset, and then focus on how to model data for RavenDB.

## Beyond relational data modeling

You've very likely used a relational database in the past. That means that you've learned about normalization, and how 
important that is. Words like data integrity are thrown around quite often, usually. But the original purpose of normalization 
had everything to do with reducing duplication to the maximum extent.

A common example for normalization is addresses. Instead of storing a customer's address on every order that he has, we'll 
simply store the address id in the order, and we have saved ourselves the need to update the address in multiple locations. 
You can see a sample of such a schema in Figure 3.1.

![A simple relational schema for orders](./Ch03/img01.png)

You've seen (and probably wrote) such schemas before. And at a glance, you'll probably agree that this is a reasonable way to 
structure a database for order management. Now, let explore what happens when the customer wishes to change his address. The 
way the database is set up, we can just update a single row in the Addresses table. Great, we're done.

Except... we've just introduce a subtle but deadly data corruption for our database. If that customer had existing orders, 
both those orders and the customer information are all pointing at the same address. Updating the address for the customer 
therefor will also update the address for _all of its orders_. When we'll look at one of those orders, we'll not see the 
address that it was shipped to, but the _current_ customer address.

> **When a data modeling error means calling the police**
> 
> In the real world, I've seen such things happen with payroll systems and paystubs (payslips across the pond). An employee 
> had married, and changed her bank account information to the new shared bank account. The couple also wanted to purchase a 
> home, so they applied for a mortgage. As part of that, they had to submit paystubs from the past several months. That 
> employee requested that HR department send her the last few stubs. When the bank saw that there were paystubs made to an 
> account that didn't even existed at that time, they suspected fraud, the mortgage was denied and the police was called. An 
> unpleasant situation all around^[This ended up being sorted out eventually, by uttering the magic words: "Computer Error", 
> for what it is worth, but it was very exciting for a while there.].

The common response for showing this issue is that it is an issue of bad modeling decisions (and I agree). The problem is that 
a more appropriate model is more complex to build and work with, more expensive to query and harder to reason about in 
general. 

A lot of the widespread wisdom about data modeling is limited to only seeing the world through relational eyes. The relation 
model offers us the Tables, Rows and Columns to store our data, and it is up to us to hammer the data to the right shape so the 
relational database can accept it. Along the way, we have to deal with an impedance mismatch between how your software (and our 
minds) model the data and how we are forced to store it to the relational database.

A document database like RavenDB doesn't solve this problem completely, it is entirely possible to construct models that would 
be a poor fit for the way RavenDB store the data. However, the way most business applications (and in general OLTP systems) 
think about their data is a really good fit for RavenDB.

You can read more about that by looking at `Domain Driven Design`^[The 
[book]( https://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215) is a bit dry, but I remember 
being very impressed when I read it the first time.] and in particular, about the notion of an `Aggregate Root`.

> **What are aggregates?**
>
> One of the best definitions I have read is [Martin Fowler](https://martinfowler.com/bliki/DDD_Aggregate.html)'s:
>  
>> A DDD aggregate is a cluster of domain objects that can be treated as a single unit. An example may be an order and its 
>> line-items, these will be separate objects, but it's useful to treat the order (together with its line items) as a single 
>> aggregate.

>> An aggregate will have one of its component objects be the aggregate root. Any references from outside the aggregate should
>> only go to the aggregate root. The root can thus ensure the integrity of the aggregate as a whole.

In the context of RavenDB, this is highly relevant, since every RavenDB document is an aggregate, and every aggregate is a 
document. Modeling techniques for aggregates works really well for document oriented design, and that give you a great reasource
for modeling in the real world. 

But before we can start running, we need to learn to walk, so let us tart by learning how to use RavenDB with the most basic of 
modeling techniques, none.

## Using RavenDB as a key/value store

RavenDB is a document database, but it is also quite good at being just a key/value store. That is mostly accidental, but as 
part of making sure that we have a really fast database, we also significantly reduced the cost of just storing and loading 
documents without any of the other benefits of RavenDB.

With the restriction that the data must be JSON, using RavenDB as a key/value store make a lot of sense. It makes a lot of 
sense to use RavenDB to cache information, store the shopping cart during purchase process or just hold on to the user session 
data, all classic models for key/value stores.

RavenDB doesn't impose any additional costs on storing / loading documents by default, so you get to use very fast database 
with the simplest of all access models. Typical complexity in key/value modeling reside in generating the appropriate key, and 
what sort of operations you can do on it.

For the purpose of using RavenDB as a key/value store, the following features are probably most relevant:

* You can generate the document key independently of the collection used.
* Loading saved document(s) can be done in a single call, by providing the id(s) to load. 
* RavenDB provide automatic expiration for documents, which you can use with caching / session data.
* You can perform searches using the document key as a prefix (and even using glob like searches).
* Includes can be used to fetch related data without having to make multiple remote calls.

The nice thing about using RavenDB as a key/value store for such information is that you aren't _limited_ to just those 
key/value operations. If you are storing shopping cart data inside RavenDB, you can also start pulling data from there. If 
you want to know what is the most popular item currently being purchases across the board, or to do projections on inventory
or any of a whole host of things that would be useful to know.

In a typical key/value store (`Redis`, for example) you'll have to manually track such things, but RavenDB allows you to 
query and aggregate the data very easily.

But using RavenDB just for key/value data is somewhat of a waste, given what it is capable of doing with your data. So, without
further ado, let us dive into document modeling in RavenDB.

## Modeling considerations in RavenDB

The reason that we cover modeling on this chapter is that I wanted you to have the chance to get a feeling for some of 
RavenDB's capabilities before we start discussing modeling techniques. This is because the kind of features that RavenDB has
to offer are directly relevant to the models you'll write.

We typically encourage you to using DDD techniques for modeling in RavenDB, since they fit so well. A core design principle 
for modeling documents is that they should be: Independent, Isolated and Coherent.

* *Independent* - a document should have its own separate existence from any other documents. 
* *Isolated* - a document can change independently from other documents. 
* *Coherent* - a document should be legible on its own, without referencing other documents.

This is actually easier to explain using negation. A document is not independent if it can't stand up on its own. A good 
example of a dependent document would be the `OrderLine`. An `OrderLine` doesn't really have a meaning outside the scope of 
an `Order`, so it should be a `Value Object` inside the `Order` document. An `Entity` is defined as "a thing with distinct and 
independent existence". And that is how you treat documents, as entities. If a document exists only as a part of larger whole, the 
model should be refactor so that single large whole is a single document.

A documnet is not isolated if changing this document also requires updating additional document(s). For example, if you update the 
`CustomerBilling` document and also need to update the `Customer` document, they are not isolated.. A document should be able to 
change independently from other documents, otherwise, there is an unclear transaction boundary involved. With each document isolated, 
the transaction boundary (what can change together) is much clearer, it is drawn at the document level.

A document is not coherent if it is not possible to make sense of the document with just the information on that document. If you need
to go and lookup additional state or information from other documents, that document isn't coherent. A good example would be the 
`Order` document and the `ShippingMethod`. If, in order to ship an order, we need to go and look at the `Customer` document, then the
`Order` document is not coherent. 

### Looking at physical documents

A really good trick for document modeling is to consider the data as, well... documents. What I mean by that, _physical_ document, 
the kind that you actually hold up in your hand and can get a paper cut from. A lot of the same considerations that apply in the real
world apply for document modeling.

If I hand you a document and tell you that you need to fill up _this_ form, and then go and update _that_ form, you'll right consider 
the process (normal goverment behavior / bureaucratic / kafkaesque)^[Circle the approach choise]. If I gave you a form and told you 
that in order to understand it you had to consult this other document... you get my point.

When modeling, I find that it really helps when I'm picture the document in its printed form. If it make sense as a printed page, it 
is probably valid in term of document modeling.

### Denormalization and other scary beasts

Anyone taking a relational modeling course had the notion that "Store a Fact Only Once" as  just short of sacred (or maybe not so 
short). The basic idea is that if you store a fact only a single time, you are preventing update anomolies. Such as when you updated 
a person date of birth in the employee record, but forgot to update it on the "send a card" listing. 

I wholeheartedly agree with this statement, in principal. But the problem is that sometimes, this isn't the same fact at all, even if
it looks the same. Let us consider the notion of a `Customer`, `Order` and what the `Address` property means in this case. The 
`Customer` entity has an `Address` property, that holds the address of the customer, and the `Order` which has a `ShipTo` proeprty.

Why are we duplicating this information? The answer is that this isn't the same information, even if the content is the same. On the 
one hand, we have the `Customer.Address` which represent the _current_ customer's address. On the other hand, we have the 
`Order.ShipTo` which represent a _point in time_ copy of the customer address at the time we created the order. Those are very 
important distinctions. 

One of the more common objections to the kind of modeling advice in this chapter is that the data is denormalized. And that is true, 
but for the most part, even if the same data appears in multiple locations, it doesn't have the same semantic meaning. And the notion
of point in time data is quite important in many fields. 

RavenDB has quite a few features that help in working with normalized data (`LoadDocument` and transformers are the two main one, 
covered in [Part II](#map-indexes).), but you need to consider whatever it make sense to traverse document references in your model or
if you are breaking document coherency. 

The most useful question that you can ask yourself at that situation is whatever you are looking at the _current_ value (need 
normalization) or the _point in time_ value (use a copy).

And with all of this information now in our head, we can turn to looking at concrete modeling scenarios and how to deal with them.

## Common modeling scenarios 

### Embedded

### One to one

### Many to one

### Many to many

## Advanced modeling scenarios

### Reference data

### Hierarchical information

### Temporal model

### Handling unbounded growth 

### Cached queries properties

